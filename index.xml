<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Dhruv Patel</title><link>https://dhruvpatel.dev/</link><description>Recent content on Dhruv Patel</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><copyright>Dhruv Patel</copyright><lastBuildDate>Thu, 29 Sep 2022 04:07:39 +0000</lastBuildDate><atom:link href="https://dhruvpatel.dev/index.xml" rel="self" type="application/rss+xml"/><item><title>Bloom Filters</title><link>https://dhruvpatel.dev/notes/cs/algorithms/bloom_filters/</link><pubDate>Thu, 29 Sep 2022 04:07:39 +0000</pubDate><guid>https://dhruvpatel.dev/notes/cs/algorithms/bloom_filters/</guid><description>API bf.add(x): adds x in the data structure x in bf: tests if x is in the data structure. Why not use Set or Dict? Bloom filters are more space efficients. They take memory lesser than the keys themselves. Cons can&amp;rsquo;t store associated data. does not support deletions. It is probabilistic data structure. That means, x in bf might have false positives. There are no false negatives. Applications Spell checkers: (40 years ago) Add the dictionary into the filter.</description><content>&lt;h2 id="api">API&lt;/h2>
&lt;ul>
&lt;li>&lt;code>bf.add(x)&lt;/code>: adds x in the data structure&lt;/li>
&lt;li>&lt;code>x in bf&lt;/code>: tests if x is in the data structure.&lt;/li>
&lt;/ul>
&lt;h2 id="why-not-use-set-or-dict">Why not use Set or Dict?&lt;/h2>
&lt;ul>
&lt;li>Bloom filters are more space efficients. They take memory lesser than the keys themselves.&lt;/li>
&lt;/ul>
&lt;h2 id="cons">Cons&lt;/h2>
&lt;ul>
&lt;li>can&amp;rsquo;t store associated data.&lt;/li>
&lt;li>does not support deletions.&lt;/li>
&lt;li>It is probabilistic data structure. That means, &lt;code>x in bf&lt;/code> might have false positives. There are no false negatives.&lt;/li>
&lt;/ul>
&lt;h2 id="applications">Applications&lt;/h2>
&lt;ul>
&lt;li>Spell checkers: (40 years ago) Add the dictionary into the filter. If the word is in the bloom filter, it is higly likely tobe correctly spelled word.&lt;/li>
&lt;li>list of forbidden password. E.g., too common password.&lt;/li>
&lt;li>Modern applications: Routers, a lot of packets incoming.&lt;/li>
&lt;/ul>
&lt;h2 id="how-does-it-work">How does it work?&lt;/h2>
&lt;ul>
&lt;li>we have a data set &lt;code>S&lt;/code> of size &lt;code>|S|&lt;/code>.&lt;/li>
&lt;li>have an array of &lt;code>n&lt;/code> bits.&lt;/li>
&lt;li>$b = \frac{n}{|S|}$ bits per element.&lt;/li>
&lt;li>have &lt;code>k&lt;/code> hash functions.&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> numpy &lt;span style="color:#66d9ef">as&lt;/span> np
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">class&lt;/span> &lt;span style="color:#a6e22e">BitArray&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">def&lt;/span> __init__(self, n):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#f92672">.&lt;/span>array &lt;span style="color:#f92672">=&lt;/span> np&lt;span style="color:#f92672">.&lt;/span>zeros((n &lt;span style="color:#f92672">&amp;gt;&amp;gt;&lt;/span> &lt;span style="color:#ae81ff">3&lt;/span>) &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#ae81ff">1&lt;/span>, dtype&lt;span style="color:#f92672">=&lt;/span>np&lt;span style="color:#f92672">.&lt;/span>uint8)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">set&lt;/span>(self, i):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> i, j &lt;span style="color:#f92672">=&lt;/span> divmod(i, &lt;span style="color:#ae81ff">8&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#f92672">.&lt;/span>array[i] &lt;span style="color:#f92672">=&lt;/span> self&lt;span style="color:#f92672">.&lt;/span>array[i] &lt;span style="color:#f92672">|&lt;/span> (&lt;span style="color:#ae81ff">1&lt;/span> &lt;span style="color:#f92672">&amp;lt;&amp;lt;&lt;/span> j)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">get&lt;/span>(self, i):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> i, j &lt;span style="color:#f92672">=&lt;/span> divmod(i, &lt;span style="color:#ae81ff">8&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> bool(self&lt;span style="color:#f92672">.&lt;/span>array[i] &lt;span style="color:#f92672">&amp;amp;&lt;/span> (&lt;span style="color:#ae81ff">1&lt;/span> &lt;span style="color:#f92672">&amp;lt;&amp;lt;&lt;/span> j))
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> xxhash
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">get_hashes_for_str&lt;/span>(x, k):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># Only h1 and h2 are computed afresh. Remaining hash &lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># functions are just linear combinations of h1 and h2.&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">assert&lt;/span> k &lt;span style="color:#f92672">&amp;gt;&lt;/span> &lt;span style="color:#ae81ff">1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> h1 &lt;span style="color:#f92672">=&lt;/span> xxhash&lt;span style="color:#f92672">.&lt;/span>xxh64_intdigest(x, seed&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">42&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> h2 &lt;span style="color:#f92672">=&lt;/span> xxhash&lt;span style="color:#f92672">.&lt;/span>xxh64_intdigest(x, seed&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">84&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> hashes &lt;span style="color:#f92672">=&lt;/span> [h1, h2]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">for&lt;/span> i &lt;span style="color:#f92672">in&lt;/span> range(&lt;span style="color:#ae81ff">2&lt;/span>, k):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> hashes&lt;span style="color:#f92672">.&lt;/span>append(h1 &lt;span style="color:#f92672">+&lt;/span> i&lt;span style="color:#f92672">*&lt;/span>h2)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> hashes
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">class&lt;/span> &lt;span style="color:#a6e22e">BloomFilter&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">def&lt;/span> __init__(self, n, k):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#f92672">.&lt;/span>array &lt;span style="color:#f92672">=&lt;/span> BitArray(n)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#f92672">.&lt;/span>k &lt;span style="color:#f92672">=&lt;/span> k
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#f92672">.&lt;/span>n &lt;span style="color:#f92672">=&lt;/span> n
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">add&lt;/span>(self, key):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">for&lt;/span> h &lt;span style="color:#f92672">in&lt;/span> get_hashes_for_str(key, self&lt;span style="color:#f92672">.&lt;/span>k):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#f92672">.&lt;/span>array&lt;span style="color:#f92672">.&lt;/span>set(h &lt;span style="color:#f92672">%&lt;/span> self&lt;span style="color:#f92672">.&lt;/span>n)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">def&lt;/span> __contains__(self, key):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">for&lt;/span> h &lt;span style="color:#f92672">in&lt;/span> get_hashes_for_str(key, self&lt;span style="color:#f92672">.&lt;/span>k):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> &lt;span style="color:#f92672">not&lt;/span> self&lt;span style="color:#f92672">.&lt;/span>array&lt;span style="color:#f92672">.&lt;/span>get(h &lt;span style="color:#f92672">%&lt;/span> self&lt;span style="color:#f92672">.&lt;/span>n):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#66d9ef">False&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#66d9ef">True&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>text &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;correct incorrect&amp;#34;&lt;/span>&lt;span style="color:#f92672">.&lt;/span>split()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>bm &lt;span style="color:#f92672">=&lt;/span> BloomFilter(&lt;span style="color:#ae81ff">10&lt;/span>, &lt;span style="color:#ae81ff">5&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">for&lt;/span> word &lt;span style="color:#f92672">in&lt;/span> text:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> bm&lt;span style="color:#f92672">.&lt;/span>add(word)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">for&lt;/span> word &lt;span style="color:#f92672">in&lt;/span> text:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">assert&lt;/span> word &lt;span style="color:#f92672">in&lt;/span> bm
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">assert&lt;/span> &lt;span style="color:#e6db74">&amp;#34;notcorrect&amp;#34;&lt;/span> &lt;span style="color:#f92672">not&lt;/span> &lt;span style="color:#f92672">in&lt;/span> bm
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="analysis">Analysis&lt;/h2>
&lt;p>Trade off between erro rate and space required. Data structre will be useful when there is a sweetspot on the tradeoff curve.&lt;/p>
&lt;p>Assumption: The hash functions are independent and they distribute the data uniformly.&lt;/p>
&lt;p>Out of n bits, focus on a particular bit. What is the probability that it has been set?&lt;/p>
&lt;p>It is probability of 1 minus it hasn&amp;rsquo;t been set by any of the &lt;code>|S|&lt;/code> elements, for any of the &lt;code>k&lt;/code> hash functions.&lt;/p>
&lt;p>$p = 1 - (1 - \frac{1}{n})^{k|S|}$.&lt;/p>
&lt;p>As can be seen by the plot below, $1+x$ can be approximated by $e^x$ when x is close to zero. In all cases, $e^x$ is an overestimate of $1+x$.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> matplotlib.pyplot &lt;span style="color:#66d9ef">as&lt;/span> plt
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>x &lt;span style="color:#f92672">=&lt;/span> np&lt;span style="color:#f92672">.&lt;/span>linspace(&lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">2&lt;/span>, &lt;span style="color:#ae81ff">2&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>plt&lt;span style="color:#f92672">.&lt;/span>plot(x, &lt;span style="color:#ae81ff">1&lt;/span>&lt;span style="color:#f92672">+&lt;/span>x, label&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;$1 +x$&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>plt&lt;span style="color:#f92672">.&lt;/span>plot(x, np&lt;span style="color:#f92672">.&lt;/span>exp(x), label&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;$e^x$&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>plt&lt;span style="color:#f92672">.&lt;/span>legend();
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;img src="images/63351a0ed542f328049edc91.png" alt="output image for above cell">&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-text" data-lang="text">&lt;span style="display:flex;">&lt;span>&amp;lt;Figure size 640x480 with 1 Axes&amp;gt;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Thus, $p \approx 1 - e^{\frac{-k|S|}{n}} = 1 - e^{\frac{-k}{b}}$. Remember, b is the bits per element.&lt;/p>
&lt;p>As $b \to \inf$, $p \to 0$.&lt;/p>
&lt;p>Thus, the probability of false positive is $\epsilon = (1-e^{\frac{-k}{b}})^k$.&lt;/p>
&lt;h2 id="how-to-set-k">How to set K?&lt;/h2>
&lt;p>Set K optimally. Fix the b, then set k to minimize the error.
Using calculus, $k \approx (ln 2) b$.&lt;/p>
&lt;p>When we plug this back into the p, we get $\epsilon \approx (\frac{1}{2})^\left((ln 2) b\right)$. Notice that error rate is exponential in b.&lt;/p>
&lt;p>Using little bit of algebra we can get $b \approx 1.44 log_2{\frac{1}{\epsilon}}$. (Hint: $1.44 \approx \frac{1}{ln2}$.)&lt;/p>
&lt;h2 id="how-does-theory-differ-from-practice">How does theory differ from practice&lt;/h2>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> string
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> random
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> numpy &lt;span style="color:#66d9ef">as&lt;/span> np
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>letters &lt;span style="color:#f92672">=&lt;/span> np&lt;span style="color:#f92672">.&lt;/span>array(list(string&lt;span style="color:#f92672">.&lt;/span>ascii_letters &lt;span style="color:#f92672">+&lt;/span> string&lt;span style="color:#f92672">.&lt;/span>digits))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">random_str&lt;/span>():
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#e6db74">&amp;#39;&amp;#39;&lt;/span>&lt;span style="color:#f92672">.&lt;/span>join(np&lt;span style="color:#f92672">.&lt;/span>random&lt;span style="color:#f92672">.&lt;/span>choice(letters, np&lt;span style="color:#f92672">.&lt;/span>random&lt;span style="color:#f92672">.&lt;/span>randint(&lt;span style="color:#ae81ff">4&lt;/span>, &lt;span style="color:#ae81ff">9&lt;/span>)))
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Generate 1M keys, and insert them in the bloom filter. Just for sanity check, I will test if there is no false negative. Then I will generate keys at random, check if it is in actually there, and how often does bloom filter give false positive. Recall that error rate as a function of b = n/10M is $\approx (\frac{1}{2})^\left((ln 2) b\right)$.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>actually_there &lt;span style="color:#f92672">=&lt;/span> set()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>set_size &lt;span style="color:#f92672">=&lt;/span> int(&lt;span style="color:#ae81ff">1e6&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">while&lt;/span> len(actually_there) &lt;span style="color:#f92672">!=&lt;/span> set_size:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> actually_there&lt;span style="color:#f92672">.&lt;/span>add(random_str())
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> tqdm.auto &lt;span style="color:#f92672">import&lt;/span> tqdm
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>bs &lt;span style="color:#f92672">=&lt;/span> [&lt;span style="color:#ae81ff">4&lt;/span>, &lt;span style="color:#ae81ff">8&lt;/span>, &lt;span style="color:#ae81ff">12&lt;/span>, &lt;span style="color:#ae81ff">16&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>fpve_rate &lt;span style="color:#f92672">=&lt;/span> []
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>theory &lt;span style="color:#f92672">=&lt;/span> []
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">for&lt;/span> b &lt;span style="color:#f92672">in&lt;/span> bs:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> theory&lt;span style="color:#f92672">.&lt;/span>append(&lt;span style="color:#ae81ff">.5&lt;/span>&lt;span style="color:#f92672">**&lt;/span>(np&lt;span style="color:#f92672">.&lt;/span>log(&lt;span style="color:#ae81ff">2&lt;/span>)&lt;span style="color:#f92672">*&lt;/span>b))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> bm &lt;span style="color:#f92672">=&lt;/span> BloomFilter(b&lt;span style="color:#f92672">*&lt;/span>set_size, k&lt;span style="color:#f92672">=&lt;/span>int(np&lt;span style="color:#f92672">.&lt;/span>log(&lt;span style="color:#ae81ff">2&lt;/span>)&lt;span style="color:#f92672">*&lt;/span>b))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">for&lt;/span> key &lt;span style="color:#f92672">in&lt;/span> tqdm(actually_there, &lt;span style="color:#e6db74">&amp;#34;Inserting&amp;#34;&lt;/span>):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> bm&lt;span style="color:#f92672">.&lt;/span>add(key)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">for&lt;/span> key &lt;span style="color:#f92672">in&lt;/span> tqdm(actually_there, &lt;span style="color:#e6db74">&amp;#34;Sanity Checking&amp;#34;&lt;/span>):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">assert&lt;/span> key &lt;span style="color:#f92672">in&lt;/span> bm
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> fpve, total &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">while&lt;/span> total &lt;span style="color:#f92672">&amp;lt;&lt;/span> &lt;span style="color:#ae81ff">10_000&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> key &lt;span style="color:#f92672">=&lt;/span> random_str()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> key &lt;span style="color:#f92672">in&lt;/span> actually_there: &lt;span style="color:#66d9ef">continue&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> key &lt;span style="color:#f92672">in&lt;/span> bm:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> fpve &lt;span style="color:#f92672">+=&lt;/span> &lt;span style="color:#ae81ff">1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> total &lt;span style="color:#f92672">+=&lt;/span> &lt;span style="color:#ae81ff">1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> fpve_rate&lt;span style="color:#f92672">.&lt;/span>append(fpve&lt;span style="color:#f92672">/&lt;/span>total)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-text" data-lang="text">&lt;span style="display:flex;">&lt;span>Inserting: 0%| | 0/1000000 [00:00&amp;lt;?, ?it/s]
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-text" data-lang="text">&lt;span style="display:flex;">&lt;span>Sanity Checking: 0%| | 0/1000000 [00:00&amp;lt;?, ?it/s]
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-text" data-lang="text">&lt;span style="display:flex;">&lt;span>Inserting: 0%| | 0/1000000 [00:00&amp;lt;?, ?it/s]
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-text" data-lang="text">&lt;span style="display:flex;">&lt;span>Sanity Checking: 0%| | 0/1000000 [00:00&amp;lt;?, ?it/s]
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-text" data-lang="text">&lt;span style="display:flex;">&lt;span>Inserting: 0%| | 0/1000000 [00:00&amp;lt;?, ?it/s]
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-text" data-lang="text">&lt;span style="display:flex;">&lt;span>Sanity Checking: 0%| | 0/1000000 [00:00&amp;lt;?, ?it/s]
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-text" data-lang="text">&lt;span style="display:flex;">&lt;span>Inserting: 0%| | 0/1000000 [00:00&amp;lt;?, ?it/s]
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-text" data-lang="text">&lt;span style="display:flex;">&lt;span>Sanity Checking: 0%| | 0/1000000 [00:00&amp;lt;?, ?it/s]
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>bs_lin &lt;span style="color:#f92672">=&lt;/span> np&lt;span style="color:#f92672">.&lt;/span>linspace(bs[&lt;span style="color:#ae81ff">0&lt;/span>], bs[&lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>plt&lt;span style="color:#f92672">.&lt;/span>plot(bs_lin, &lt;span style="color:#ae81ff">.5&lt;/span>&lt;span style="color:#f92672">**&lt;/span>(np&lt;span style="color:#f92672">.&lt;/span>log(&lt;span style="color:#ae81ff">2&lt;/span>)&lt;span style="color:#f92672">*&lt;/span>bs_lin), label&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;Theory&amp;#34;&lt;/span>, c&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;b&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>plt&lt;span style="color:#f92672">.&lt;/span>plot(bs, theory, &lt;span style="color:#e6db74">&amp;#39;o&amp;#39;&lt;/span>, c&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;b&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>plt&lt;span style="color:#f92672">.&lt;/span>plot(bs, fpve_rate, &lt;span style="color:#e6db74">&amp;#39;-x&amp;#39;&lt;/span>, label&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;Practice&amp;#34;&lt;/span>, c&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;orange&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>plt&lt;span style="color:#f92672">.&lt;/span>legend();
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>plt&lt;span style="color:#f92672">.&lt;/span>xlabel(&lt;span style="color:#e6db74">&amp;#34;bits per element&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-text" data-lang="text">&lt;span style="display:flex;">&lt;span>Text(0.5, 0, &amp;#39;bits per element&amp;#39;)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;img src="images/63351a0ed542f328049edc92.png" alt="output image for above cell">&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-text" data-lang="text">&lt;span style="display:flex;">&lt;span>&amp;lt;Figure size 640x480 with 1 Axes&amp;gt;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>fpve_rate
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-text" data-lang="text">&lt;span style="display:flex;">&lt;span>[0.1551, 0.0211, 0.0024, 0.0003]
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>at b=12, false positive rate is already less than 1%&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;/code>&lt;/pre>&lt;/div></content></item><item><title>CM-Notes</title><link>https://dhruvpatel.dev/notes/physics/theoretical_minimum/cm-notes/</link><pubDate>Wed, 28 Sep 2022 01:08:59 +0000</pubDate><guid>https://dhruvpatel.dev/notes/physics/theoretical_minimum/cm-notes/</guid><description>Notation $ F_i(\{q\}) $ is the force on ith particle. $ \{q\} $ is the set of cordinates of all particles.
If there are N particles in the system,
Configration space: 3N dimensional space, records positions.
State space: 6N dimensional space, records position and velocity.
Phase space: 6N dimesnional space, records position and momentum.
Newton&amp;rsquo;s second law gives us 6N equations.
$$ \begin{align*} \dot{p}_i &amp;amp;= F_i(\{q\}) \\ \dot{q}_i &amp;amp;= \frac{p_i}{m_i} \end{align*} $$</description><content>&lt;h2 id="notation">Notation&lt;/h2>
&lt;p>$ F_i(\{q\}) $ is the force on ith particle. $ \{q\} $ is the set of cordinates of all particles.&lt;/p>
&lt;p>If there are N particles in the system,&lt;/p>
&lt;p>Configration space: 3N dimensional space, records positions.&lt;/p>
&lt;p>State space: 6N dimensional space, records position and velocity.&lt;/p>
&lt;p>Phase space: 6N dimesnional space, records position and momentum.&lt;/p>
&lt;h2 id="newtons-second-law">Newton&amp;rsquo;s second law&lt;/h2>
&lt;p>gives us 6N equations.&lt;/p>
&lt;p>$$
\begin{align*}
\dot{p}_i &amp;amp;= F_i(\{q\}) \\
\dot{q}_i &amp;amp;= \frac{p_i}{m_i}
\end{align*}
$$&lt;/p>
&lt;p>Thus, if forces are known, we can compute trajectory in 6N dimensional configration space.&lt;/p>
&lt;p>if we denote $ p = \sum_{i=1}^{i=N} p_i $,&lt;/p>
&lt;h2 id="newtons-third-law">Newton&amp;rsquo;s third law,&lt;/h2>
&lt;pre>&lt;code>every force has equal and opposite reaction
&lt;/code>&lt;/pre>
&lt;p>can be used to derive conservation of momentum.&lt;/p>
&lt;p>$\dot{p} = 0$.&lt;/p>
&lt;p>What this tells us is if we start our trajectory at some 6N-D point in configration space, all the points in the trajectory have the same momentum. In some sense, system evolves on a contour of constant momentum.&lt;/p>
&lt;h2 id="energy">Energy&lt;/h2>
&lt;p>Potential Energy Principle: All forces derive from a potential energy function $V(\{q\})$.&lt;/p>
&lt;p>For particle moving in 1 dimension,&lt;/p>
&lt;p>$ F(q) = -\frac{dV(q)}{dq}$.&lt;/p>
&lt;p>Potential energy can be computed as $V(q) = - \int_{-\infty}^q F(q&amp;rsquo;) dq&amp;rsquo;$.&lt;/p>
&lt;p>Potential energy is not conserved. Sum of potential energy and kinetic energy are conserved.&lt;/p>
&lt;p>Kinetic energy: $T = \frac{1}{2} mv^2$.&lt;/p>
&lt;p>More than one particles, three dimensions. If the system has N particles, the i in $q_i$ can index any of the 3N elements of the configration space.&lt;/p>
&lt;p>Principle:
For &lt;strong>any&lt;/strong> system there exists a potential function $V(\{q\})$, such that,&lt;/p>
&lt;p>$$
F_i(\{q\}) = - \frac{\partial V(\{q\})}{\partial q_i}
$$&lt;/p>
&lt;p>In general mathematics such function need not exist for a collection of $F_i$s. This law represents conservation of energy.&lt;/p>
&lt;h2 id="lagrangian">Lagrangian&lt;/h2>
&lt;h3 id="for-one-particle-in-one-dimension">For one particle in one dimension&lt;/h3>
&lt;p>We are given $q(t_0)$ and $q(t_1)$.&lt;/p>
&lt;p>$L(q, \dot{q}) = T - V = \frac{1}{2}m\dot{q}^2 - V(\{q\})$&lt;/p>
&lt;p>Action $A = \int_{t_0}^{t_1} L dt$.&lt;/p>
&lt;p>Principle of least action tells that the particle chooses a trajectory (the function q) which minimizes the the action.&lt;/p>
&lt;p>Principle of least action gives Euler-Lagrange equations.&lt;/p>
&lt;p>$$
\frac{d}{dt} \frac{\partial L}{\partial \dot{q}} - \frac{\partial L}{\partial {q}} = 0
$$&lt;/p>
&lt;h3 id="for-multidimensional-motion-of-many-particles">For multidimensional motion of many particles&lt;/h3>
&lt;p>Euler-Lagrange equations are given by,&lt;/p>
&lt;p>$L(\{q\}, \{\dot{q}\}) = \sum_i \frac{1}{2}m_i\dot{q}_i^2 - V(\{q\})$.&lt;/p>
&lt;p>$$
\frac{d}{dt} \frac{\partial L}{\partial \dot{q}_i} - \frac{\partial L}{\partial {q_i}} = 0
$$&lt;/p>
&lt;p>Lagrangian packs all the equations of the motions concisely.&lt;/p>
&lt;p>$\frac{\partial L}{\partial \dot{q}_i}$ is called generalized momentum conjugate to $q_i$. This can be motiviated by thinking of $q_i$ as cartesian coordinates and $L = \frac{1}{2}m\dot{x}^2$. Depending upon the Lagrangian, conjugate momentum may not have familiar form, but it is always difined by the formula $p_i =\frac{\partial L}{\partial \dot{q}_i}$.&lt;/p>
&lt;p>So, if the Lagrangian does not depend on $q_i$, $\dot{p}_i = 0$, i.e. the conjugate momentum is conserved. Such coordinates are called cyclic coordinates.&lt;/p>
&lt;h4 id="another-example-of-cylic-coordinates">Another example of cylic coordinates&lt;/h4>
&lt;p>$ L = \frac{m}{2}(\dot{x}_1^2 + \dot{x}_2^2 ) + V(x_1 - x_2)$. It does look like that L is a function of $x_1$ and $x_2$, so neither of these is cyclic coordinate. But, if we do change of variables,
$$
\begin{align*}
x_+ &amp;amp;= \frac{x_1+x_2}{2} \\
x_- &amp;amp;= \frac{x_1-x_2}{2}
\end{align*}
$$&lt;/p>
&lt;p>the Lagrangian can be rewritten as, $L = m(\dot{x}_+^2 + \dot{x}_-^2 ) + V(2x_-)$. Now the momentum conjugate to $x_+$ is conserved. $p_+ = 2m\dot{x}_+ = m(\dot{x}_1 + \dot{x}_2)$, so the total momentum is conserved.&lt;/p>
&lt;p>If $ L = \frac{m}{2}(\dot{q_1}^2 + \dot{q_2}^2 ) + V(a q_1 - b q_2)$, then&lt;/p>
&lt;p>$$
\begin{align*}
\dot{p}_1 &amp;amp;= -a V(a q_1 - b q_2) \\
\dot{p}_2 &amp;amp;= b V(a q_1 - b q_2) \\
\end{align*} \text{.}
$$&lt;/p>
&lt;p>Law of conservation of momentum has changed. Instead of conserving $p_1 + p_2$, $bp_1+ap_2$ is conserved. If V was a non linear function of $q_1, q_2$, there wouldn&amp;rsquo;t be law of conservation.&lt;/p>
&lt;h2 id="symmetries">Symmetries&lt;/h2>
&lt;p>$q_i&amp;rsquo; = q_i&amp;rsquo;(q_i)$. We are moving the whole system to the new location. This change changes the system. For example, potential energy(so the Lagrangian) may change.&lt;/p>
&lt;p>Symmetry is the coordinate transformation that does not change the value of the Lagrangian.&lt;/p>
&lt;h3 id="examples">Examples&lt;/h3>
&lt;p>$L = \frac{1}{2} \dot{q}^2$. And the transformation $ q \rightarrow q + \delta$. Here the $\dot{q}$ does not change, so L also doesn&amp;rsquo;t change.&lt;/p>
&lt;p>If the Lagrangian had a potential ($V(q)$) term in it, unless the potential is a constant independent of q, change in q changes the potential. In that case there is no symmetry.&lt;/p>
&lt;h4 id="example-sym1">Example Sym.1&lt;/h4>
&lt;p>If, potential was a function $V(q_1 - q_2)$, then under the transformation
$$
\begin{align*}
q_1 &amp;amp;\rightarrow q_1 + \delta \\
q_2 &amp;amp;\rightarrow q_2 + \delta
\end{align*}
$$
L is symmetric.&lt;/p>
&lt;h4 id="example-sym2">Example Sym.2&lt;/h4>
&lt;p>If, potential was a function $V(aq_1 + bq_2)$, then under the transformation
$$
\begin{align*}
q_1 &amp;amp;\rightarrow q_1 + b\delta \\
q_2 &amp;amp;\rightarrow q_2 - a\delta
\end{align*}
$$
L is symmetric.&lt;/p>
&lt;h4 id="example-sym3">Example Sym.3&lt;/h4>
&lt;p>If, $ L = \frac{1}{2} (\dot{x}^2 + \dot{y}^2) + V(x^2 + y^2)$, then there is rotational symmetry. That is, rotating the point around origin by angle $\theta$ does not change the lagrangian.&lt;/p>
&lt;p>$$
\begin{align*}
x &amp;amp;\rightarrow x cos\theta + y sin\theta \\
y &amp;amp;\rightarrow -x sin\theta + y cos\theta
\end{align*}
$$&lt;/p>
&lt;p>For small angle $\delta$, $sin\delta = \delta$ and $cos\delta = 1$.
$$
\begin{align*}
x &amp;amp;\rightarrow x + y \delta \\
y \rightarrow -x \delta + y &amp;amp;= y - x\delta
\end{align*}
$$
Plugging this into the lagrangian, we can see that (in the first order of $\delta$) lagrangian does not change.&lt;/p>
&lt;h3 id="general-notion-of-symmetry">General notion of symmetry&lt;/h3>
&lt;p>In general, the shift is parameterized by infinitesimal $\delta$ and is given by $\delta q_i = f_i(q) \delta$.&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>example&lt;/th>
&lt;th>$f_1$&lt;/th>
&lt;th>$f_2$&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>Sym.1&lt;/td>
&lt;td>1&lt;/td>
&lt;td>1&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Sym.2&lt;/td>
&lt;td>b&lt;/td>
&lt;td>-a&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Sym.3&lt;/td>
&lt;td>y&lt;/td>
&lt;td>-x&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>Change in velocity then is given by $\delta \dot{q_i} = \frac{d}{dt} \delta q_i$.&lt;/p>
&lt;p>A continuous symmetry is an infinitesimal transformation of the coordinates for which the change in the Lagrangian is zero.&lt;/p>
&lt;p>If we assume that system evolves along a trajectory that satisfies Euler-Lagrangian equations, we can prove that symmetry implies $\cal{Q}$ is conserved. Where $\cal{Q} = \sum_i p_i f_i(q)$.&lt;/p>
&lt;p>Applying this to &lt;strong>Sym.3&lt;/strong>, we see that $l = p_x y - p_y x$, aka angular momentum, is conserved.&lt;/p>
&lt;h2 id="time-translation-invariance">Time translation invariance&lt;/h2>
&lt;p>A system is time-translation invariant if there is no explicit time dependence in its Lagrangian.&lt;/p>
&lt;p>e.g. harmonic motion due to spring $L(x, \dot{x}) = \frac{1}{2} (m \dot{x}^2 - k x^2)$. Here neither the mass m, nor the spring constant k depend on the time.&lt;/p>
&lt;p>If spring constant changes with time i.e. k(t), there would be no time translation invariance.&lt;/p>
&lt;p>Now if $L = L(q_i, \dot{q}_i, t)$,&lt;/p>
&lt;p>$$
\frac{dL}{dt} = \sum_i \left( \frac{\partial{L}}{\partial{q_i}} \dot{q}_i + \frac{\partial{L}}{\partial{\dot{q}_i}} \ddot{q}_i \right) + \frac{\partial{L}}{\partial{t}}
$$&lt;/p>
&lt;p>Using Euler-Lagrangian equations, we can simplify above to&lt;/p>
&lt;p>$$
\frac{dL}{dt} = \frac{d}{dt} \sum_i p_i \dot{q}_i + \frac{\partial{L}}{\partial{t}} \text{.}
$$&lt;/p>
&lt;p>If we define $H = \sum_i p_i \dot{q}_i - L$, we see that
$$\frac{dH}{dt} = -\frac{\partial{L}}{\partial{t}} \text{.}$$&lt;/p>
&lt;p>Conclusion: H changes only if L has &lt;strong>explicit&lt;/strong> time dependence. In other words, if the system is time-translaction invariant then quantity H is conserved.&lt;/p>
&lt;p>H is called Hamiltonian, and is an energy of the system.&lt;/p>
&lt;h3 id="example-motion-of-a-particle-in-a-potential">Example: Motion of a particle in a potential&lt;/h3>
&lt;p>$$
\begin{align*}
L &amp;amp;= \frac{1}{2}m \dot{x}^2 - V(x) \\
p &amp;amp;= \frac{\partial{L}}{\partial{\dot{x}}} = m \dot{x} \\
H &amp;amp;= p \dot{x} - L \\
&amp;amp;= m \dot{x}^2 - \frac{1}{2}m \dot{x}^2 + V(x) \\
&amp;amp;= \frac{1}{2}m \dot{x}^2 + V(x) \\
\end{align*}
$$&lt;/p>
&lt;p>There are systems for which the Lagrangian has a more intricate form than just T - V. For some of those cases, it is not possible to identify a clear separation into kinetic and potential energy.&lt;/p>
&lt;p>General Definition of Energy: Energy equals Hamiltonian.&lt;/p>
&lt;p>In Lagrangian formulation, the focus is on the trajectory in the configuration space. here, the equations are second order. So knowing just the $q_i$s is not enough. We also need initial velocities.&lt;/p>
&lt;p>In Hamiltonian formulation, the focus in on the trajectory in the phase space.&lt;/p>
&lt;p>The first step in the Hamiltonian formulation is to replace $\dot{q}$&amp;rsquo;s with $p$&amp;rsquo;s. This is easy to do in normal cartesian coordinates.&lt;/p>
&lt;p>in the particle on a line, $ H = \frac{1}{2} m \dot{x}^2 + V(x)$. Replacing $\dot{x} = \frac{p}{m}$, we get, $ H = \frac{p^2}{2m} + V(x)$.&lt;/p>
&lt;p>$$
\frac{\partial H}{\partial x} = -\frac{dV}{dx}
$$&lt;/p>
&lt;p>Using $f = ma$ we can rewrite the above equations as
$$
\dot{p} = -\frac{\partial H}{\partial x}
$$&lt;/p>
&lt;p>Thus we have two equations,&lt;/p>
&lt;p>$$
\begin{align*}
-\frac{\partial H}{\partial x} &amp;amp;= \dot{p} \\
\frac{\partial H}{\partial p} = \frac{p}{m} &amp;amp;= \dot{x}
\end{align*}
$$&lt;/p>
&lt;h3 id="general-system">General system&lt;/h3>
&lt;p>$$
\begin{align*}
H &amp;amp;= H(q_i, p_i) \\
\dot{p_i} &amp;amp;= -\frac{\partial H}{\partial q_i} \\
\dot{q_i} &amp;amp;= \frac{\partial H}{\partial p}
\end{align*}
$$&lt;/p>
&lt;p>So we see that for each direction in phase space, there is a single first-order equation. If we know initial $p, q$, using above equations we can predict the future.&lt;/p>
&lt;h4 id="harmonic-oscillator">Harmonic Oscillator&lt;/h4>
&lt;p>$$
L = \frac{m \dot{x}^2}{2} - \frac{kx^2}{2}
$$&lt;/p>
&lt;p>With the change of variable $q = (km)^{\frac{1}{4}}$,&lt;/p>
&lt;p>$$
L = \frac{\dot{q}^2}{2\omega} - \frac{\omega q^2}{2}
$$&lt;/p>
&lt;p>The conjugate momentum $p = \frac{\partial L}{\partial \dot{q}} = \frac{\dot{q}}{\omega}$. This gives us $H = \frac{\omega}{2} (p^2 + q^2)$. (Exercise. Recall: $H = \sum_i p_i \dot{q}_i - L$.)&lt;/p>
&lt;p>From that,&lt;/p>
&lt;p>$$
\begin{align}
\dot{p} &amp;amp;= -\omega q \\
\dot{q} &amp;amp;= \omega p
\end{align}
$$&lt;/p>
&lt;p>Thus Hamiltonian formulation gives us two first order equations.&lt;/p>
&lt;p>Solving Euler-Lagrangian equation, on the other hand gives us single second order equation. $\ddot{q} = \omega \dot{p}$. These two are equivalent, and can be seen by substituting the first equation in the time derivative of the second equation of the Hamiltonian.&lt;/p>
&lt;p>Notice that because of constant energy, in the phase space the particle moves along a circle of fixed radius.&lt;/p>
&lt;p>&lt;img src="images/attachment:767ea6b5-3f7f-4b7f-9d23-a82fe7abc155.png" alt="image.png">&lt;/p>
&lt;h2 id="phase-space-fluid">Phase Space Fluid&lt;/h2>
&lt;p>One can imagine a trajectory starting with arbitrary point &lt;code>(p, q)&lt;/code> in the phase following the hamiltonian equations.&lt;/p>
&lt;p>$$
\begin{align*}
\dot{p_i} &amp;amp;= -\frac{\partial H}{\partial q_i} \\
\dot{q_i} &amp;amp;= \frac{\partial H}{\partial p}
\end{align*}
$$&lt;/p>
&lt;p>We can imagine the phase space made of infinite points. This can be seen as a fluid in a phase space. The fluid moves using hamiltonian equations.&lt;/p>
&lt;p>This flow has certain features.&lt;/p>
&lt;ol>
&lt;li>If a point starts at given energy H(q, p), it remains with the same value of energy.
The surfaces of the energy are defined by $H(q, p) = E$. For each value of E, we have a surface.&lt;/li>
&lt;/ol>
&lt;p>In ordinary 3-d space, a flow can be described as a velocity field $\vec{v}(x, y, z)$. For each point, it defines a velocity at that point. This can also be a function of time.&lt;/p>
&lt;p>&lt;img src="images/attachment:beee651f-3d52-42fb-95fb-028ec81d6cf7.png" alt="image.png">&lt;/p>
&lt;dl>
&lt;dt>Incompressible fluid&lt;/dt>
&lt;dd>a given amount of the fluid always occupies the same volume. It also means that the density of the fluid—the number of molecules per unit volume—is uniform and stays that way forever.&lt;/dd>
&lt;/dl>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;/code>&lt;/pre>&lt;/div></content></item><item><title>Power and Politics in Today’s World</title><link>https://dhruvpatel.dev/notes/politics/power/</link><pubDate>Sat, 10 Sep 2022 09:07:23 +0000</pubDate><guid>https://dhruvpatel.dev/notes/politics/power/</guid><description>Lecture 2 Aug 19, 1991 Moskow: Coup d&amp;rsquo;etat against Mikhail Gorbichov (came power in Feb 1985)
When came to power in 1985, west thought what would become of Soviet Union?
Gorbachev was younger, talked like a western politician, allowed criticism of the regime. His policies were more open. It seemed like it was starting to change. In 1989 while revolution in Eastern Europe, Russia didn&amp;rsquo;t intervene; this was opposite to Russia&amp;rsquo;s earlier policies.</description><content>&lt;h1 id="lecture-2">Lecture 2&lt;/h1>
&lt;p>&lt;strong>Aug 19, 1991 Moskow&lt;/strong>: &lt;a href="https://en.wikipedia.org/wiki/1991_Soviet_coup_d%27%C3%A9tat_attempt">Coup d&amp;rsquo;etat against Mikhail Gorbichov&lt;/a> (came power in Feb 1985)&lt;/p>
&lt;p>When came to power in 1985, west thought what would become of Soviet Union?&lt;/p>
&lt;p>Gorbachev was younger, talked like a western politician, allowed criticism of the regime. His policies were more open. It seemed like it was starting to change. In 1989 while revolution in Eastern Europe, Russia didn&amp;rsquo;t intervene; this was opposite to Russia&amp;rsquo;s earlier policies. He was seen as a radical reformer. He was getting push back for his ideas.&lt;/p>
&lt;p>So in 1991 hardliners from the same party did a coup d&amp;rsquo;etat.&lt;/p>
&lt;p>Yeltsin (then elected president) declared that the coup d&amp;rsquo;état was illegal. The military also said that they didn&amp;rsquo;t support the coup.&lt;/p>
&lt;p>Boris Yelstin&lt;/p>
&lt;ul>
&lt;li>Initially supported Gorbachev&amp;rsquo;s reforms.&lt;/li>
&lt;li>He thought they should have been faster.&lt;/li>
&lt;li>He resigned from communist party in 1987. This was unprecedented then.&lt;/li>
&lt;li>It&amp;rsquo;s said that he even tried to do a suicide at one point.&lt;/li>
&lt;li>Eventually ran for a member of Russian parliament.&lt;/li>
&lt;li>June 1991, he was elected president of Russian parliament.&lt;/li>
&lt;/ul>
&lt;p>Without the support of the military, coup failed. Gorbachev didn&amp;rsquo;t leave the party, and fired the people from the party members involved in the coup. As the aftermath, Yelstin gained more popularity and power moved from Gorbachev to Yeltsin.&lt;/p>
&lt;p>Agenda&lt;/p>
&lt;ol>
&lt;li>why did ussr collapse&lt;/li>
&lt;li>why was it peaceful&lt;/li>
&lt;li>rise of gangster capitalism&lt;/li>
&lt;li>yelstin to putin&lt;/li>
&lt;li>why is Russia so corrupt and lessons from it.&lt;/li>
&lt;/ol>
&lt;p>&lt;img src="images/final_days_of_ussr.png" alt="final_days">&lt;/p>
&lt;h2 id="why-did-ussr-collapse">Why did USSR collapse?&lt;/h2>
&lt;ul>
&lt;li>Stores were empty.&lt;/li>
&lt;li>Government department store (7 story building) was empty.&lt;/li>
&lt;li>People making decisions didn&amp;rsquo;t have much/correct data.&lt;/li>
&lt;li>Prices were not set using supply and demand.&lt;/li>
&lt;li>System became unsustainable.&lt;/li>
&lt;li>&lt;a href="https://en.wikipedia.org/wiki/Containment">Containment&lt;/a> (policy by George Kennan, ambassador to Russia) worked.&lt;/li>
&lt;li>1979: Involved in Afghanistan. Spent 1980s in this war. Failed war was a fiscal drain.&lt;/li>
&lt;li>Ronald Reagan announced Star Wars. Which increased the cost of the arm race.&lt;/li>
&lt;/ul>
&lt;h2 id="why-was-the-collapse-peaceful">Why was the collapse peaceful?&lt;/h2>
&lt;p>Why did elites gave up the power?
Comment from audience: Elites found ways to protect themselves from a collapse.&lt;/p>
&lt;p>&lt;a href="https://en.wikipedia.org/wiki/Exit,_Voice,_and_Loyalty">Albert Hirschman&amp;rsquo;s framework (1970)&lt;/a>&lt;/p>
&lt;p>How do we people response to decline?&lt;/p>
&lt;ol>
&lt;li>leave&lt;/li>
&lt;li>complain and get it changed (voice)&lt;/li>
&lt;li>try to change it by yourself&lt;/li>
&lt;/ol>
&lt;p>Which step to take depends on the cost.&lt;/p>
&lt;p>For example, a public company badly run&lt;/p>
&lt;ul>
&lt;li>Sell the shares&lt;/li>
&lt;li>You might be loyal to the company (get is changed), workers would use voice (cost of exit is high).&lt;/li>
&lt;/ul>
&lt;p>Collapse of loyalty from the elites and citizens by 1991.&lt;/p>
&lt;ul>
&lt;li>Evidence of brazen corruption (by professor&amp;rsquo;s first hand experience)&lt;/li>
&lt;li>Elites didn&amp;rsquo;t believe the ideology of the country&lt;/li>
&lt;/ul>
&lt;p>If you are not loyal, and the cost of exit is low, why stay and change the organization?&lt;/p>
&lt;p>What reduced the cost of exit?&lt;/p>
&lt;ul>
&lt;li>Reduced political costs of exit
&lt;ul>
&lt;li>Yeltsin exited the party to become a president&lt;/li>
&lt;li>Eduard Shevardnadze was a foreign minister of the Soviet Union, became president of Georgia&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Reduced economic costs of exit&lt;/li>
&lt;/ul>
&lt;h2 id="the-rise-of-oligarchs">The rise of oligarchs&lt;/h2>
&lt;p>Result of the collapse.&lt;/p>
&lt;ul>
&lt;li>In 1980s agencies (including KGP) started moving money offshore, to live another day to fight, in case of collapse. In 1991 beurocracy disappeared. Many people found themselves in control of unmanaged, unsupervised bank accounts.&lt;/li>
&lt;li>Theft of state assets.
&lt;ul>
&lt;li>Rem Viakhirev (deputi minister of Oil and Gas) was in charge of Gazprom (state venture controlling gas in Soviet Union)
&lt;ul>
&lt;li>he started giving away large assets to relatives and friends at below market price and pocketed the differences.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Russia had inherited weak and bankrupt state
&lt;ul>
&lt;li>1990s fiscal crisis for USSR, massive debts, fiscally strapped. And many people took advantage of it for example by lending money to the government in return for state assets which they got to keep, because government couldn&amp;rsquo;t pay it back.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="yeltsin-to-putin">Yeltsin to Putin&lt;/h2>
&lt;ul>
&lt;li>Last years of the Soviet Union was a weak state, the party however was strong.&lt;/li>
&lt;/ul>
&lt;p>Symptoms of a weak state?&lt;/p>
&lt;ul>
&lt;li>inability to tax (low capacity to raise revenue, didn&amp;rsquo;t have a capacity to audit oil companies for example)
&lt;ul>
&lt;li>Throughout the 1990s oligargs lobbied NOT to improve capacity to raise oil taxes&lt;/li>
&lt;li>Putin said he was determined the tax system (he did)&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Haphazard use of power
&lt;ul>
&lt;li>Putin took down Khodorkovsky, (reclaimed the assets)&lt;/li>
&lt;li>Putin took down Vyakhirev, (reclaimed the assets)&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="why-russia-is-corrupt">Why Russia is Corrupt.&lt;/h2>
&lt;ol>
&lt;li>Path dependence (historian&amp;rsquo;s) story&lt;/li>
&lt;li>Resource Curse (aka oil curse) (political economist&amp;rsquo;s) story&lt;/li>
&lt;/ol>
&lt;ul>
&lt;li>
&lt;p>40% of Russian govenments revenue from oil&lt;/p>
&lt;/li>
&lt;li>
&lt;p>leads to corruption.&lt;/p>
&lt;p>If only way to get rich in Russia is to have access to the oil sector, then people who control the access will charge premium to get the access.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>If oil prices fall, government&amp;rsquo;s revenue also falls.&lt;/p>
&lt;h3 id="why-dont-they-diversify">Why don&amp;rsquo;t they diversify?&lt;/h3>
&lt;ul>
&lt;li>Beneficiaries like it this way.&lt;/li>
&lt;li>Government needs it: weak state&lt;/li>
&lt;li>A source of geopolitical power (e.g. germany was a top importer from Russia)&lt;/li>
&lt;/ul></content></item><item><title>QM-Notes</title><link>https://dhruvpatel.dev/notes/physics/theoretical_minimum/qm-notes/</link><pubDate>Fri, 26 Aug 2022 08:08:31 +0000</pubDate><guid>https://dhruvpatel.dev/notes/physics/theoretical_minimum/qm-notes/</guid><description>Quantum Mechanics Differences from Classical Mechanics States have different logical structure than CM. States and measurements are different unlike CM. e.g. Position and Momemntum can be determined by experiments in CM. Spins Particles have properties attached to it. e.g. mass, electric charge.
Even a specific particle is not completely specified by its position.
Attached to electron is an extra degree of freedom, called spin. Spin is as quantum mechanical as it can and we should not try to visualize it.</description><content>&lt;h1 id="quantum-mechanics">Quantum Mechanics&lt;/h1>
&lt;h2 id="differences-from-classical-mechanics">Differences from Classical Mechanics&lt;/h2>
&lt;ol>
&lt;li>States have different logical structure than CM.&lt;/li>
&lt;li>States and measurements are different unlike CM. e.g. Position and Momemntum can be determined by experiments in CM.&lt;/li>
&lt;/ol>
&lt;h2 id="spins">Spins&lt;/h2>
&lt;p>Particles have properties attached to it. e.g. mass, electric charge.&lt;/p>
&lt;p>Even a specific particle is not completely specified by its position.&lt;/p>
&lt;p>Attached to electron is an extra degree of freedom, called spin. Spin is as quantum mechanical as it can and we should not try to visualize it.&lt;/p>
&lt;h2 id="testing">Testing&lt;/h2>
&lt;p>Propositions:
$$
\begin{align*}
A &amp;amp;: \sigma_z = +1 \\
B &amp;amp;: \sigma_x = +1 \\
\end{align*}
$$&lt;/p>
&lt;h3 id="classically">Classically,&lt;/h3>
&lt;p>To test (A or B), one could first &lt;strong>gently&lt;/strong> test $\sigma_z$. If it is -1, one would &lt;strong>gently&lt;/strong> test $\sigma_x$. The result of doing it otherway (i.e. B or A) will be the same as doing (A or B). The reason is that classically, measurements are gentle. They don&amp;rsquo;t change the state of the system.&lt;/p>
&lt;h3 id="in-quantum-mechanics">In Quantum Mechanics,&lt;/h3>
&lt;p>If some entity prepares the spin in $\sigma_z = +1$ state, and we measure &lt;code>A or B&lt;/code> (whether we use short circuit or not), we will measure it to be true. However, if we measure &lt;code>B or A&lt;/code>, there is 25% chance that we will measure it to be false.&lt;/p>
&lt;p>What about &lt;code>A and B&lt;/code>? If we conclude that &lt;code>A and B&lt;/code> is true, can we confirm it again? Answer is no. Since to compute B, we had to measure $\sigma_x$, which ruined measurement of A. Thus we can&amp;rsquo;t confirm it. i.e. experiment is not reproducible.&lt;/p>
&lt;h2 id="complex-numbers">Complex Numbers&lt;/h2>
&lt;p>Two ways to represent them.&lt;/p>
&lt;p>In cartesian coordinates, $z = x + iy$.&lt;/p>
&lt;p>In polar coordinates, $z = re^{i\theta}$.&lt;/p>
&lt;p>$ x_1 x_2 = (r_1e^{i\theta_1})(r_2e^{i\theta_2}) = r_1 r_2 e^{i(\theta_1 + \theta_2)}$.&lt;/p>
&lt;p>$z = x + iy = re^{i\theta}$&lt;/p>
&lt;p>$z^\ast = x - iy = re^{-i\theta}$&lt;/p>
&lt;p>$z^\ast z = r^2$, i.e. a real number&lt;/p>
&lt;h3 id="phase-factors">Phase Factors&lt;/h3>
&lt;p>These are complex numbers whose r componenet is 1. Following holds for them,&lt;/p>
&lt;p>$$
\begin{align}
z^\ast z &amp;amp;= 1 \\
z &amp;amp;= e^{i\theta}\\
z &amp;amp;= \cos\theta + i \sin\theta
\end{align}
$$&lt;/p>
&lt;h2 id="vector-spaces">Vector Spaces&lt;/h2>
&lt;p>Vector spaces is familiar concept from abstract linear algebra.&lt;/p>
&lt;h3 id="complex-conjugate-of-space-v">Complex Conjugate of space V&lt;/h3>
&lt;p>For every $\ket{A}$ there exists $\bra{A}$ in conjugate space. This space has following properties.&lt;/p>
&lt;ol>
&lt;li>The conjugate of $\ket{A} + \ket{B}$ is $\bra{A}+\bra{B}$.&lt;/li>
&lt;li>Conjugate of $z\ket{A}$ is $z^\ast \bra{A} = \bra{A}z^\ast $.&lt;/li>
&lt;/ol>
&lt;p>In the concrete case where ket space is column vectors, bra space is denoted as row vectors.&lt;/p>
&lt;p>i.e. if&lt;/p>
&lt;p>$$
\begin{align*}
\ket{A} = \begin{bmatrix}
\alpha_1 \\
\alpha_2 \\
\vdots \\
\alpha_n
\end{bmatrix}
\end{align*}
$$&lt;/p>
&lt;p>then
$$
\begin{align*}
\bra{A} = \begin{bmatrix}
\alpha_1^\ast &amp;amp; \alpha_2^\ast &amp;amp; \dots &amp;amp; \alpha_n^\ast
\end{bmatrix}.
\end{align*}
$$&lt;/p>
&lt;h3 id="inner-products">Inner Products&lt;/h3>
&lt;p>Inner product is always between bras and kets. It is written like $\braket{B}{A}$. The result is a complex numbers.&lt;/p>
&lt;h4 id="axioms-of-inner-product">Axioms of inner product.&lt;/h4>
&lt;ol>
&lt;li>Inner product is linear. $\bra{C} + (\ket{A}+\ket{B}) = \braket{C}{A} + \braket{C}{B}$.&lt;/li>
&lt;li>$\braket{B}{A} = \braket{A}{B}^\ast $.&lt;/li>
&lt;/ol>
&lt;h4 id="special-vectors">Special vectors&lt;/h4>
&lt;ol>
&lt;li>Normalized: $\braket{A}{A} = 1$.&lt;/li>
&lt;li>Orhthogonal: $\braket{B}{A} = 0$.&lt;/li>
&lt;/ol>
&lt;h3 id="orhtonormal-basis">Orhtonormal Basis.&lt;/h3>
&lt;p>Let our space be N dimensional. And let the orthonomal basis denoted by $\ket{i}$.&lt;/p>
&lt;p>$$
\ket{A} = \sum_i \alpha_i \ket{i},
$$&lt;/p>
&lt;p>where, $\alpha_j = \braket{j}{A}$.&lt;/p>
&lt;h1 id="states">States&lt;/h1>
&lt;p>In CM, knowing the state means knowing everything that is necessary to predict the future.&lt;/p>
&lt;p>In QM, knowing the state means knowing as much as can be known about how the system was prepared.&lt;/p>
&lt;p>Apparatus $\cal{A}$ can be oriented on any axis. If we orient it along z axis, the measured spin will either be +1 or -1.&lt;/p>
&lt;p>$\sigma_z = \pm 1$. We can denote +1 as state $\ket{u}$ and -1 as $\ket{d}$.&lt;/p>
&lt;p>Similarly $\sigma_x = \pm 1$, can be denoted by $\ket{r}$ and -1 as $\ket{l}$. And $\sigma_y = \pm 1$, can be denoted by $\ket{o}$ and -1 as $\ket{i}$.&lt;/p>
&lt;p>If two states are orthogonal than these two states can be determined together. For example, if $\sigma_z$ was prepared to be in $\ket{u}$, for any subsequent measurements probability that $\ket{d}$ is detected is 0. Thus for binary spin, the state space is two dimensional. For now we can take $\ket{u}, \ket{d}$ as the basis vectors.&lt;/p>
&lt;p>Then, the generic state $\ket{A} = \alpha_u \ket{u} + \alpha_d \ket{d}$. Where $\alpha_i = \braket{i}{A}$.&lt;/p>
&lt;p>The meaning of,&lt;/p>
&lt;ul>
&lt;li>$\alpha_u^\ast \alpha_u$: If the spin was prepared in $\ket{A}$ state, $\alpha_u^\ast \alpha_u$ is the probability that $\sigma_z = +1$.&lt;/li>
&lt;li>$\alpha_d^\ast \alpha_d$: is the probability that $\sigma_z = -1$.&lt;/li>
&lt;/ul>
&lt;p>Since probabilities must add to 1, $\alpha_u^\ast \alpha_u + \alpha_d^\ast \alpha_d = 1$. It is equivalent to saying that $\ket{A}$ is normalized, i.e. $\braket{A}{A} = 1$.&lt;/p>
&lt;p>General principle of quantum systems: the state of a system is represented by a unit (normalized) vector in a vector space of states. Moreover, the squared magnitudes of the components of the state-vector, &lt;strong>along particular basis vectors&lt;/strong>, represent probabilities for various experimental outcomes.&lt;/p>
&lt;h3 id="representing-ketr-and-ketl-using-above-basis-vectors">Representing $\ket{r}$ and $\ket{l}$ using above basis vectors&lt;/h3>
&lt;p>We know that if A initially prepares the state in $\ket{r}$, $\sigma_z = \pm 1$ with equal probability. Hence, $\alpha_u^\ast \alpha_u =\alpha_d^\ast \alpha_d = \frac{1}{2}$. One choice is to have $\alpha_u = \alpha_d = \frac{1}{\sqrt{2}}$.&lt;/p>
&lt;p>$\ket{r} = \frac{1}{\sqrt{2}} \ket{u} + \frac{1}{\sqrt{2}} \ket{d}$. (There are is still ambiguity, called phase ambiguity.)&lt;/p>
&lt;p>To solve for $\ket{l}$ the above process repeats. But, in addition, $\braket{l}{r} = 0$. One choice is $[\frac{1}{\sqrt{2}}, -\frac{1}{\sqrt{2}}]$. But it is not the only choice. Even for fixed choice for $\ket{r}$, you can multiply above choice by a phase factor ($z = e^{i\theta}$), and still satisfy the two constraints. Later, we will find out that no measurable quantity is sensitive to the overall phase-factor, and therefore we can ignore it when specifying states.&lt;/p>
&lt;h3 id="representing-keti-and-keto-using-above-basis-vectors">Representing $\ket{i}$ and $\ket{o}$ using above basis vectors&lt;/h3>
&lt;p>To solve for $\ket{i}$ and $\ket{o}$, we need same conditions as we needed above. But we also need additional constrains. For example, if A prepares the state in $ket{i}$,$\sigma_x = \pm1$, with equal probability. Also $\braket{i}{o} = 0$.&lt;/p>
&lt;p>The following solution solves for these constraints (up to phase-factor ambiguity).&lt;/p>
&lt;p>$\ket{i} = \frac{1}{\sqrt{2}} \ket{u} + \frac{i}{\sqrt{2}} \ket{d}$.&lt;/p>
&lt;p>$\ket{o} = \frac{1}{\sqrt{2}} \ket{u} - \frac{i}{\sqrt{2}} \ket{d}$.&lt;/p>
&lt;p>With the previous discussion, the vectors can be represented in column format as below.&lt;/p>
&lt;p>$$
\begin{align*}
\ket{u} &amp;amp;= \begin{bmatrix} 1 \\ 0 \end{bmatrix}, \ket{d} = \begin{bmatrix} 0 \\ 1 \end{bmatrix} \\
\end{align*}
$$&lt;/p>
&lt;h3 id="matricies">Matricies&lt;/h3>
&lt;p>Axiom: Physical observables are described by linear operators.&lt;/p>
&lt;p>observables are the things that we can measure. e.g. coordinates of a particle; the energy, momentum, or angular momentum of a system; or the electric field at a point in space.&lt;/p>
&lt;p>$$
\begin{align*}
M \ket{A} &amp;amp;= \ket{B} \\
M \sum_j \alpha_j \ket{j} &amp;amp;= \sum_j \beta_j \ket{j} \\
\sum_j \alpha_j M\ket{j} &amp;amp;= \sum_j \beta_j \ket{j} &amp;lt;\text{assuming M is linear}&amp;gt; \\
\sum_j \alpha_j \bra{k} M \ket{j} &amp;amp;= \sum_j \beta_j \braket{k}{j} &amp;lt;\text{multiply both sides by} \bra{k}&amp;gt; \\
\sum_j \alpha_j m_{kj} &amp;amp;= \beta_k\\
\end{align*}
$$&lt;/p>
&lt;p>Note that each $m_{kj}$ is a complex number. We can think of M in terms of matrix (defined by a choice of basis vectors).&lt;/p>
&lt;h4 id="eigenvectors-and-eigenvalues">Eigenvectors and Eigenvalues&lt;/h4>
&lt;p>$M \ket{\lambda} = \lambda \ket{\lambda}$. $\lambda$ is an eigenvalue, and $\ket{\lambda}$ is an eigenvector.&lt;/p>
&lt;h4 id="linear-operators-on-bra-vectors">Linear operators on bra vectors&lt;/h4>
&lt;p>$$
\begin{align*}
B^\ast &amp;amp;= \begin{bmatrix} b_1^\ast &amp;amp; b_2^\ast &amp;amp; b_3^\ast \end{bmatrix} \\
M &amp;amp;= \begin{bmatrix}
m_{11} &amp;amp; m_{12} &amp;amp; m_{13} \\
m_{21} &amp;amp; m_{22} &amp;amp; m_{23} \\
m_{31} &amp;amp; m_{32} &amp;amp; m_{33} \\
\end{bmatrix}
\end{align*}
$$&lt;/p>
&lt;p>Than $\bra{B} M$ is just row vector multiplied by matrix M.&lt;/p>
&lt;h4 id="hermitian-conjugate">Hermitian Conjugate&lt;/h4>
&lt;p>$$
\begin{align*}
M^\dagger &amp;amp;= (M^T)^\ast \\
M \ket{A} &amp;amp;= \ket{B} \\
\bra{A} M^\dagger &amp;amp;= \bra{B} \\
\end{align*}
$$&lt;/p>
&lt;h4 id="hermitian-operators">Hermitian Operators&lt;/h4>
&lt;ul>
&lt;li>Observables quantities in classcial mechanics are real numbers. i.e. they are their own complex conjugate.&lt;/li>
&lt;li>Observables in quantum mechanics (i.e. linear operators) are also their own complex conjugates. Such operators are called Hermitian Operators. $M^\dagger = M$.&lt;/li>
&lt;/ul>
&lt;h5 id="properties-of-hermitian-operators">Properties of Hermitian Operators&lt;/h5>
&lt;ul>
&lt;li>Their eigenvalues are real.&lt;/li>
&lt;li>Their eigenvectors form an orthonormal basis. (i.e. their eigenvectors are orthonormal and they form a basis)&lt;/li>
&lt;/ul>
&lt;h2 id="principles">Principles&lt;/h2>
&lt;ol>
&lt;li>The observable or measurable quantities of QM are represented by a linear operator L.&lt;/li>
&lt;li>The possible readings of the measurements are eigenvalues $\lambda_i$. The state for which reading is &lt;strong>unambiguously&lt;/strong> $\lambda_i$ is the corresponding eigenvector $\ket{\lambda_i}$.&lt;/li>
&lt;li>Unambiguously distinguishable states are represented by orthogonal vectors. e.g. $\braket{u}{d} = 0$.&lt;/li>
&lt;li>If $\ket{A}$ is the state vector of the system, and the observable L is measured, the probability of observing $\lambda_i$ is given by $\braket{A}{\lambda_i}\braket{\lambda_i}{A}$.&lt;/li>
&lt;/ol>
&lt;p>Since the readings (i.e. eigenvalues) are real and eigenvectors are orthogonal, the operator L must be hermitian.&lt;/p>
&lt;h3 id="3-vector-operator-sigma">3-Vector Operator $\sigma$&lt;/h3>
&lt;ul>
&lt;li>Just as a spin-measuring apparatus can only answer questions about a spin&amp;rsquo;s orientation in a specific direction, a spin operator can only provide information about the spin component in a specific direction.&lt;/li>
&lt;li>To physically measure spin in a different direction, we need to rotate the apparatus to point in the new direction. The same idea applies to the spin operator—if we want it to tell us about the spin component in a new direction, it too must be &amp;ldquo;rotated&amp;rdquo; but this kind of rotation is accomplished mathematically.&lt;/li>
&lt;/ul>
&lt;h3 id="operator-matrices">Operator Matrices&lt;/h3>
&lt;p>Using above four principles, and solving linear equations, we can derive them.&lt;/p>
&lt;p>$$
\sigma_z = \begin{bmatrix}
1 &amp;amp; 0 \\
0 &amp;amp; -1
\end{bmatrix}, \sigma_x = \begin{bmatrix}
0 &amp;amp; 1 \\
1 &amp;amp; 0
\end{bmatrix}, \sigma_y = \begin{bmatrix}
0 &amp;amp; -i \\
i &amp;amp; 0
\end{bmatrix} \text{.}
$$&lt;/p>
&lt;p>These along with Identity matrix are called Pauli Matrices.&lt;/p>
&lt;p>IMPORTANT: Applying the operator L to state $\ket{A}$ does not change the state to $L\ket{A}$. $L\ket{A}$ is actually a supuerposition and tells us the probabilities of basis states. When we actually measure using L, the system is changed to one of the eignestates unambiguously.&lt;/p>
&lt;p>There is nothing special about these three operators. We can take any direction $\hat{n} = (n_x, n_y, n_z)$, orient the apparatus A along $\hat n$, activate A, and measure the component of the spin along $\hat n$. That means there has to be an operator that represents this operation. Indeed, this operator is given by $\sigma_n = \sigma \cdot \hat n$, where $\sigma = (\sigma_x, \sigma_y, \sigma_z)$.&lt;/p>
&lt;p>$$
\sigma_n = \begin{bmatrix}
n_z &amp;amp; (n_x - i n_y) \\
(n_x + i n_y) &amp;amp; -n_z
\end{bmatrix}
$$&lt;/p>
&lt;h3 id="spin-polarization-principle">Spin-Polarization Principle&lt;/h3>
&lt;p>For any state $\ket{A} = \alpha_u \ket{u} + \alpha_d \ket{d}$, there exists some direction $\hat n$ such that $\sigma \cdot \hat n = \ket{A}$.&lt;/p>
&lt;p>States of the spins are characterized by a polarization vector, and along the polarization vector the component of the spin is predictably +1.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;/code>&lt;/pre>&lt;/div></content></item><item><title>Convex Optimization</title><link>https://dhruvpatel.dev/notes/maths/convex_optimization/convex_optimization/</link><pubDate>Fri, 26 Aug 2022 07:31:53 +0000</pubDate><guid>https://dhruvpatel.dev/notes/maths/convex_optimization/convex_optimization/</guid><description>Convex Optimization Note: These notes are not mathematically rigorous. These are meant for quick reference, please read the Convex Optimization book from Boyd and Vandenberghe for more rigorous treatment.
Chapter 2: Convex Sets Sets Affine Sets Affine combination: $\sum_{i=1}^{i=N} \theta_i x_i$ such that $\sum_{i=1}^{i=N} \theta_i = 1$.
Draw a line passing through any two points, if the whole line is in the set, the set is affine.
Every affine set C can be written as $C = V + x_0$ for any $x_0 \in C$, where V is a subspace.</description><content>&lt;h1 id="convex-optimization">Convex Optimization&lt;/h1>
&lt;!--eofm-->
&lt;p>Note:
These notes are not mathematically rigorous. These are meant for quick reference, please read the &lt;a href="https://web.stanford.edu/~boyd/cvxbook/">Convex Optimization book&lt;/a> from Boyd and Vandenberghe for more rigorous treatment.&lt;/p>
&lt;h2 id="chapter-2-convex-sets">Chapter 2: Convex Sets&lt;/h2>
&lt;h3 id="sets">Sets&lt;/h3>
&lt;h4 id="affine-sets">Affine Sets&lt;/h4>
&lt;p>Affine combination: $\sum_{i=1}^{i=N} \theta_i x_i$ such that $\sum_{i=1}^{i=N} \theta_i = 1$.&lt;/p>
&lt;p>Draw a line passing through any two points, if the whole line is in the set, the set is affine.&lt;/p>
&lt;p>Every affine set C can be written as $C = V + x_0$ for any $x_0 \in C$, where V is a subspace.&lt;/p>
&lt;dl>
&lt;dt>Affine Hull of C (&lt;strong>aff&lt;/strong> C)&lt;/dt>
&lt;dd>Smallest affine set, which contains C.&lt;/dd>
&lt;dt>Affine Dimension&lt;/dt>
&lt;dd>Dimension of an affine hull.&lt;/dd>
&lt;dt>Relative Interior&lt;/dt>
&lt;dd>&lt;strong>relint&lt;/strong> C = {x ∈ C | B(x, r) ∩ aff C ⊆ C for some r &amp;gt; 0}.&lt;/dd>
&lt;dt>Boundary&lt;/dt>
&lt;dd>&lt;strong>cl&lt;/strong> C - &lt;strong>relint&lt;/strong> C&lt;/dd>
&lt;/dl>
&lt;h5 id="example">Example&lt;/h5>
&lt;p>Let C = $\{x \in R^3 | −1 \le x_1 \le 1, −1 \le x_2 \le 1, x_3 = 0\}$. That is a square.&lt;/p>
&lt;ul>
&lt;li>Interior: Empty&lt;/li>
&lt;li>Relative interior: square without the border&lt;/li>
&lt;li>Boundary: the perimeter&lt;/li>
&lt;/ul>
&lt;h4 id="convex-sets">Convex Sets&lt;/h4>
&lt;dl>
&lt;dt>Convex combination&lt;/dt>
&lt;dd>$\sum_{i=1}^{i=N} \theta_i x_i$ such that $\sum_{i=1}^{i=N} \theta_i = 1$ and $\theta_i \ge 0$.&lt;/dd>
&lt;/dl>
&lt;p>Draw a line segment between any two points, if the whole line segment is in the set, the set is convex.&lt;/p>
&lt;h4 id="cones">Cones&lt;/h4>
&lt;dl>
&lt;dt>Cone&lt;/dt>
&lt;dd>A set C is called a cone, if for every x ∈ C and θ ≥ 0 we have $\theta x \in C$&lt;/dd>
&lt;dt>Convex Cone&lt;/dt>
&lt;dd>A set C is convex cone, if it is convex and a cone!&lt;/dd>
&lt;dt>Conic Combination&lt;/dt>
&lt;dd>$\sum_{i=1}^{i=N} \theta_i x_i$ such that $\theta_i \ge 0$.&lt;/dd>
&lt;/dl>
&lt;h3 id="some-important-examples">Some Important Examples&lt;/h3>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>example&lt;/th>
&lt;th>affine?&lt;/th>
&lt;th>convex?&lt;/th>
&lt;th>convex cone?&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>hyperplane&lt;/td>
&lt;td>Y&lt;/td>
&lt;td>Y&lt;/td>
&lt;td>Y&lt;sup>1&lt;/sup>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>halfspace&lt;/td>
&lt;td>N&lt;/td>
&lt;td>Y&lt;/td>
&lt;td>Y&lt;sup>1&lt;/sup>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>norm ball&lt;/td>
&lt;td>N&lt;/td>
&lt;td>Y&lt;/td>
&lt;td>N&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>norm cones&lt;/td>
&lt;td>N&lt;/td>
&lt;td>Y&lt;/td>
&lt;td>Y&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>polyhedra&lt;/td>
&lt;td>&lt;/td>
&lt;td>Y&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>positive definite cone&lt;/td>
&lt;td>&lt;/td>
&lt;td>Y&lt;/td>
&lt;td>Y&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;ol>
&lt;li>Only if 0 is in the set.&lt;/li>
&lt;/ol>
&lt;dl>
&lt;dt>Hyperplane&lt;/dt>
&lt;dd>$\{x | a^T x = b\} = \{x | a^T(x-x_0) = 0\}$ for constant vector a and scalar b. Where $x_0$ is any point in the hyperplane.&lt;/dd>
&lt;dt>Closed Half spaces&lt;/dt>
&lt;dd>$\{x | a^T x \le b\}$&lt;/dd>
&lt;dt>Euclidean Ball&lt;/dt>
&lt;dd>$B(x_c, r) = \{ x \, | \, \| x - x_c \|_2 \le r \} = \{ x_c + ru \, | \, \| u \|_2 \le 1\}$.&lt;/dd>
&lt;dt>Ellipsoid&lt;/dt>
&lt;dd>$ E = \{ x \, | \, (x - x_c)^T P^{-1} (x-x_c) \le 1 \} = \{ x_c + Au \, | \, \| u \|_2 \le 1 \}$. Where, P is positive definite matrix, and A is square and non singular matrix.&lt;/dd>
&lt;dt>Norm Cones&lt;/dt>
&lt;dd>$\{ (x, t) \, | \, \| x \| \le t\} \subset R^{n+1}$.&lt;/dd>
&lt;dt>Second order cone (Lorentz cone)&lt;/dt>
&lt;dd>Norm cone where norm is euclidean norm.&lt;/dd>
&lt;dt>Polyhedron&lt;/dt>
&lt;dd>A polyhedron is thus the intersection of a finite number of halfspaces and hyperplanes.&lt;/dd>
&lt;dt>Simplex&lt;/dt>
&lt;dd>Simplex is a special polyhedron. If $v_0, \dots, v_k$ are affinely independent (that is $v_1-v_0, \dots , v_k-v_0$ are linearly independent) then simplex is just convex hull of $(v_0, \dots, v_k)$.&lt;/dd>
&lt;/dl>
&lt;h3 id="operations-that-preseve-convexity">Operations that preseve convexity&lt;/h3>
&lt;h4 id="intersection">Intersection&lt;/h4>
&lt;p>If $S_\alpha$ is a convex set for for every $\alpha \in \cal{A}$ where $\cal{A}$ is any set (could be uncountable infinite), then $\cap_{\alpha \in \cal{A}} S_\alpha$ is also convex. Converse is also true. Every closed convex set S is a (usually infinite) intersection of halfspaces.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> numpy &lt;span style="color:#66d9ef">as&lt;/span> np
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> matplotlib.pyplot &lt;span style="color:#66d9ef">as&lt;/span> plt
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>x &lt;span style="color:#f92672">=&lt;/span> np&lt;span style="color:#f92672">.&lt;/span>linspace(&lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">2&lt;/span>, &lt;span style="color:#ae81ff">2&lt;/span>, num&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">100&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>ts &lt;span style="color:#f92672">=&lt;/span> np&lt;span style="color:#f92672">.&lt;/span>linspace(&lt;span style="color:#f92672">-&lt;/span>np&lt;span style="color:#f92672">.&lt;/span>pi&lt;span style="color:#f92672">/&lt;/span>&lt;span style="color:#ae81ff">3&lt;/span>, np&lt;span style="color:#f92672">.&lt;/span>pi&lt;span style="color:#f92672">/&lt;/span>&lt;span style="color:#ae81ff">3&lt;/span>, num&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">20&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">S&lt;/span>(t):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> c1, c2 &lt;span style="color:#f92672">=&lt;/span> np&lt;span style="color:#f92672">.&lt;/span>array([np&lt;span style="color:#f92672">.&lt;/span>cos(t), np&lt;span style="color:#f92672">.&lt;/span>cos(&lt;span style="color:#ae81ff">2&lt;/span>&lt;span style="color:#f92672">*&lt;/span>t)])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> c, m &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">1&lt;/span>&lt;span style="color:#f92672">/&lt;/span>c2, c1&lt;span style="color:#f92672">/&lt;/span>c2
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> (&lt;span style="color:#66d9ef">lambda&lt;/span> x: c &lt;span style="color:#f92672">-&lt;/span> m&lt;span style="color:#f92672">*&lt;/span>x, &lt;span style="color:#66d9ef">lambda&lt;/span> x: &lt;span style="color:#f92672">-&lt;/span>c &lt;span style="color:#f92672">-&lt;/span> m&lt;span style="color:#f92672">*&lt;/span>x)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">for&lt;/span> t &lt;span style="color:#f92672">in&lt;/span> ts:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> y1, y2 &lt;span style="color:#f92672">=&lt;/span> S(t)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> plt&lt;span style="color:#f92672">.&lt;/span>plot(x, y1(x), &lt;span style="color:#e6db74">&amp;#39;k&amp;#39;&lt;/span>, lw&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;.5&amp;#39;&lt;/span>);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> plt&lt;span style="color:#f92672">.&lt;/span>plot(x, y2(x), &lt;span style="color:#e6db74">&amp;#39;k&amp;#39;&lt;/span>, lw&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;.5&amp;#39;&lt;/span>);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>plt&lt;span style="color:#f92672">.&lt;/span>ylim(&lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">2&lt;/span>, &lt;span style="color:#ae81ff">2&lt;/span>);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>plt&lt;span style="color:#f92672">.&lt;/span>xlim(&lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">2&lt;/span>, &lt;span style="color:#ae81ff">2&lt;/span>);
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;img src="images/5c5d61291f1a421f53dc37afdf5908e5.png" alt="output image for above cell">&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-text" data-lang="text">&lt;span style="display:flex;">&lt;span>&amp;lt;Figure size 432x288 with 1 Axes&amp;gt;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h4 id="affine-functions">Affine Functions&lt;/h4>
&lt;p>Function f is affine if f = Ax + b for some A and b.&lt;/p>
&lt;p>If S is convex then the image of S under f (i.e. $f(S) = \{f(x) | x \in S\}$) is also convex.&lt;/p>
&lt;p>If g is a function such that the image of g is S and S is convex, then the inverse image of S (i.e. $\{x | g(x) \in S\}$) is also convex.&lt;/p>
&lt;dl>
&lt;dt>Hyperbolic Cone&lt;/dt>
&lt;dd>$\{ x | x^T P x \le (c^T x)^2, c^T x \ge 0 \}$&lt;/dd>
&lt;/dl>
&lt;h4 id="perspective-function">Perspective Function&lt;/h4>
&lt;p>$P: R^{n+1} \to R^n$, where &lt;strong>dom&lt;/strong> P = $R^n \times R_{++}$. P is defined as $P(z, t) = z/t$.&lt;/p>
&lt;p>If domain of P is convex then the image of P is also convex.&lt;/p>
&lt;h4 id="linear-fractional-function">Linear Fractional Function&lt;/h4>
&lt;p>Combination of Perspective and affine.&lt;/p>
&lt;p>$$
f(x) = \frac{Ax+b}{c^T x + d}
$$&lt;/p>
&lt;p>where $c^Tx+d &amp;gt; 0$.&lt;/p>
&lt;p>If C is convex, then $f(C)$ is also convex.&lt;/p>
&lt;p>If C is convex, then $f^{-1}(C)$ is also convex.&lt;/p>
&lt;h3 id="generalized-inequalities">Generalized Inequalities&lt;/h3>
&lt;dl>
&lt;dt>Proper Cone&lt;/dt>
&lt;dd>A cone is proper if it is convex, closed, solid (non empty interior) and is pointed (it does not contain a line).&lt;/dd>
&lt;dt>Generalized inequality with respect to proper cone K&lt;/dt>
&lt;dd>$ x \le_K y \iff y - x \in K$. Also $ x &amp;lt;_K y \iff y-x \in \textbf{int} K$&lt;/dd>
&lt;/dl>
&lt;p>Examples&lt;/p>
&lt;ol>
&lt;li>$ K = R^n_+ $. Then for vectors x and y, $x \le y$ iff $x_i \le y_i$ for all i.&lt;/li>
&lt;li>$ K = S^n_+ $. Then for matrices A and B, $A \le B$ iff $B - A$ is positive semidefinite.&lt;/li>
&lt;/ol>
&lt;h4 id="minimum-and-minimal">Minimum and Minimal&lt;/h4>
&lt;dl>
&lt;dt>Minimum&lt;/dt>
&lt;dd>$x \in S$ is the minimum if for every $y \in S$ we have $ x \le y$.&lt;/dd>
&lt;dt>Minimal&lt;/dt>
&lt;dd>$x \in S$ is a minimal if $y \in S, y \le x$ only if $y = x$.&lt;/dd>
&lt;/dl>
&lt;h3 id="separating-hyperplane">Separating Hyperplane&lt;/h3>
&lt;p>If C and D are disjoint convex set, there exists a and b such that $a^T x \ge b$ for all x in D and $a^T x \le b$ for all x in C.&lt;/p>
&lt;p>If C is a convex and $x_0 \notin C$. Then $x_0$ and C can be strictly separated.&lt;/p>
&lt;p>Converse of above theorem is not true. That is there may exist convex sets C and D which are separated by a hyperplane, they still might intersect. Simple example is $C = D = \{0\} \subset R$. $x = 0$ separates C and D.&lt;/p>
&lt;p>Converse holds if C and D are convex and C is open set.&lt;/p>
&lt;p>Thus, any two convex sets C and D, at least one of which is open, are disjoint &lt;strong>iff&lt;/strong> there exists a separating hyperplane.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;/code>&lt;/pre>&lt;/div></content></item><item><title>Analysis (Not Rigorous) Notes</title><link>https://dhruvpatel.dev/notes/maths/analysis/</link><pubDate>Sun, 10 Jul 2022 18:37:29 +0530</pubDate><guid>https://dhruvpatel.dev/notes/maths/analysis/</guid><description>Definitions Interior Point $x \in C$ A point is an interior point if we can find a ball around x which is completely inside C. Open Set A set is open, if all points are interior points. Closed Set A set is closed, if its complement is open. Closure Take the set&amp;rsquo;s complement. Find its interior. Take the complement of it. You got a closure. A point is in a closure, if for every $\epsilon$, you can find a point from the original set within $\epsilon$ distance.</description><content>&lt;h2 id="definitions">Definitions&lt;/h2>
&lt;dl>
&lt;dt>Interior Point $x \in C$&lt;/dt>
&lt;dd>A point is an interior point if we can find &lt;strong>a&lt;/strong> ball around x which is completely inside C.&lt;/dd>
&lt;dt>Open Set&lt;/dt>
&lt;dd>A set is open, if all points are interior points.&lt;/dd>
&lt;dt>Closed Set&lt;/dt>
&lt;dd>A set is closed, if its complement is open.&lt;/dd>
&lt;dt>Closure&lt;/dt>
&lt;dd>Take the set&amp;rsquo;s complement. Find its interior. Take the complement of it. You got a closure.&lt;/dd>
&lt;dd>
&lt;p>A point is in a closure, if for &lt;strong>every&lt;/strong> $\epsilon$, you can find a point from the original set within $\epsilon$ distance.&lt;/p>
&lt;/dd>
&lt;dt>Boundary&lt;/dt>
&lt;dd>take the closure and remove the interior.&lt;/dd>
&lt;/dl>
&lt;h2 id="examples">Examples&lt;/h2>
&lt;p>For example, closure of (-1, 1) in real line is given by complement of the interior of the (-inf, 1] U [1, inf). Which is the complement of (-inf, 1) U (1, inf), which is [-1, 1].&lt;/p></content></item><item><title>Can we do better than NumPy in special cases?</title><link>https://dhruvpatel.dev/posts/matrix_vector/</link><pubDate>Sun, 10 Apr 2022 09:11:23 +0530</pubDate><guid>https://dhruvpatel.dev/posts/matrix_vector/</guid><description>Can we? Yes. This blog explains how I did. If you want to follow the whole code, you can download the source code from GitHub repository.
Why would we? Good question. NumPy is great. It is fast. Beating it would be hard. Even if we beat it, will it be worth it? Probably not. You would quote Donald Knuth and say that premature optimization is the root of all evil. I am trying to justify this blog by asking What if this is not a premature optimization?</description><content>&lt;h2 id="can-we">Can we?&lt;/h2>
&lt;p>Yes. This blog explains how I did. If you want to follow the whole code, you can download the source code from &lt;a href="https://github.com/DhruvPatel01/notebooks/tree/main/High_Performance_Computing/mat_vec">GitHub repository.&lt;/a>&lt;/p>
&lt;h2 id="why-would-we">Why would we?&lt;/h2>
&lt;p>Good question. NumPy is great. It is fast. Beating it would be hard. Even if we beat it, will it be worth it? Probably not. You would quote Donald Knuth and say that premature optimization is the root of all evil. I am trying to justify this blog by asking What if this is not a premature optimization? I would have tried other optimizations, and now I would want to see if I can squeeze out anything else.&lt;/p>
&lt;p>To quote Pavlo Andy, when money is involved, constants matter. Even if I can outperform NumPy by a measly 10%, it could be worth it at scale.&lt;/p>
&lt;p>I will be focusing on a problem of matrix vector multiplication. This is not a toy problem. Many machine learning algorithms ultimately just boil down to computing cosine distance between candidate vectors with anchor vector, at least during inference. You can replace cosine with dot, if you store normalized vectors into your datastore. I will also assume that the number of rows in my matrix is &amp;lt;1000. This is also a reasonable assumption. We might not want to wait to batch user requests if we don&amp;rsquo;t want to sacrifice latencies.&lt;/p>
&lt;h2 id="how-could-we">How could we?&lt;/h2>
&lt;p>So, here is what I am thinking. &lt;code>np.dot&lt;/code> works, but it is general. It might need to check for continuity, data layout, etc. In production setting, I might know these variables a priory. What if I just skip these checks? Furthermore, I don&amp;rsquo;t know what happens under the hood in NumPy. Sure, &lt;code>np.show_config()&lt;/code> can tell me if NumPy was compiled with &lt;code>BLAS&lt;/code> or not. But, does it use all the optimizations available when I actually make a call to &lt;code>np.dot&lt;/code>?&lt;/p>
&lt;p>I did try Numba. But, this is just a dot product. Nothing much complicated. Numba&amp;rsquo;s performance was no good than NumPy.&lt;/p>
&lt;p>Similarly, just lowering the computation to C is not going to beat it. Surely, NumPy does the same thing, but in a more sophisticated manner. I will have to use some &lt;code>BLAS&lt;/code> implementation. I will report my numbers using &lt;code>BLIS&lt;/code>&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>, though I have also tried OpenBLAS&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup>, and the numbers were similar. I am picking BLIS over OpenBLAS, as I have some experience of using it in the course &lt;a href="https://www.cs.utexas.edu/users/flame/laff/pfhp/">Programming for high performance&lt;/a> from the authors of BLIS, and I think for this simple matrix vector computation, both should be equally optimized. I am not using MKL as I am using AMD processor, and I have read reports that MKL does not perform well on AMD.&lt;/p>
&lt;p>My NumPy installation showed OpenBLAS in &lt;code>np.show_config()&lt;/code>. So this is a fair comparison.&lt;/p>
&lt;h3 id="step-1-installing-blisor-openblas-or-something-else">Step 1: Installing BLIS(or OpenBLAS, or something else).&lt;/h3>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>git clone https://github.com/flame/blis.git
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>cd blis
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>./configure -t openmp -p ~/blis auto
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>make -j8
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>make check -j8
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>make install
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This will install the header files and static library respectively into &lt;code>~/blis/include/blis&lt;/code> and &lt;code>~/blis/lib/libblis.a&lt;/code>. I will use these when I compile a wrapper around a BLAS &lt;code>dgemv&lt;/code> call. &lt;code>dgemv&lt;/code> stands for Generalized Matrix Vector multiplication. &lt;code>d&lt;/code> prefix means that inputs are double precision floating points. For FP32 you would use &lt;code>sgemv&lt;/code>.&lt;/p>
&lt;div class="collapsable-code">
&lt;input id="726538419" type="checkbox" checked />
&lt;label for="726538419">
&lt;span class="collapsable-code__language">bash&lt;/span>
&lt;span class="collapsable-code__title">OpenBLAS Installation&lt;/span>
&lt;span class="collapsable-code__toggle" data-label-expand="△" data-label-collapse="▽">&lt;/span>
&lt;/label>
&lt;pre class="language-bash" >&lt;code>
git clone https://github.com/xianyi/OpenBLAS.git
cd OpenBLAS
make PREFIX=/home/dhruv/OpenBLAS
make PREFIX=/home/dhruv/OpenBLAS install
&lt;/code>&lt;/pre>
&lt;/div>
&lt;h3 id="step-2-write-and-compile-a-wrapper-around-blas">Step 2: Write and compile a wrapper around BLAS.&lt;/h3>
&lt;p>As you might have noticed, BLAS routines are also general (hence the g in gemv). The &lt;code>bli_dgemv&lt;/code>&lt;sup id="fnref:3">&lt;a href="#fn:3" class="footnote-ref" role="doc-noteref">3&lt;/a>&lt;/sup> computes $y := \beta y + \alpha * trans(A)* conjugate(x)$. Yup, we could conjugate a vector even if we are working with real numbers! I am not sure how it works here, I am not going to use transpose and conjugate features anyway. In my case, $\beta = 0, \alpha=1$.&lt;/p>
&lt;p>The general signature of &lt;code>bli_dgemv&lt;/code> is&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-c" data-lang="c">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">void&lt;/span> &lt;span style="color:#a6e22e">bli_dgemv&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> (
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> trans_t transa,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> conj_t conjx,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> dim_t m,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> dim_t n,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">double&lt;/span>&lt;span style="color:#f92672">*&lt;/span> alpha,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">double&lt;/span>&lt;span style="color:#f92672">*&lt;/span> a, inc_t rsa, inc_t csa,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">double&lt;/span>&lt;span style="color:#f92672">*&lt;/span> x, inc_t incx,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">double&lt;/span>&lt;span style="color:#f92672">*&lt;/span> beta,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">double&lt;/span>&lt;span style="color:#f92672">*&lt;/span> y, inc_t incy
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> );
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ul>
&lt;li>&lt;code>transa&lt;/code> tells blis if we want to transpose A before the multiplication. I don&amp;rsquo;t, so I will use &lt;code>BLIS_NO_TRANSPOSE&lt;/code>.&lt;/li>
&lt;li>&lt;code>conjx&lt;/code> tells blis if we want to conjugate x. I don&amp;rsquo;t, so I will use &lt;code>BLIS_NO_CONJUGATE&lt;/code>.&lt;/li>
&lt;li>m is the number of rows of A.&lt;/li>
&lt;li>n is the number of columns of A.&lt;/li>
&lt;li>$\alpha, \beta$ were explained earlier.&lt;/li>
&lt;li>&lt;code>double *a&lt;/code>, is a pointer to the matrix A. I will have stored the matrix in row major order, so &lt;code>rsa&lt;/code>(row stride) will be &lt;code>n&lt;/code> and &lt;code>csa&lt;/code>(column stride) will be 1.&lt;/li>
&lt;li>&lt;code>x&lt;/code> is a pointer to array where x, the vector we want to multiply A with, stays.&lt;/li>
&lt;li>&lt;code>y&lt;/code> is a pointer to array where Ax will be saved.&lt;/li>
&lt;li>&lt;code>incx&lt;/code> and &lt;code>incy&lt;/code> will be 1 as I know I have continuous arrays &lt;code>x&lt;/code> and &lt;code>y&lt;/code>.&lt;/li>
&lt;/ul>
&lt;div class="collapsable-code">
&lt;input id="712863945" type="checkbox" />
&lt;label for="712863945">
&lt;span class="collapsable-code__language">c&lt;/span>
&lt;span class="collapsable-code__title">gemv_blis.c&lt;/span>
&lt;span class="collapsable-code__toggle" data-label-expand="△" data-label-collapse="▽">&lt;/span>
&lt;/label>
&lt;pre class="language-c" >&lt;code>
#include &amp;#34;blis.h&amp;#34;
void blis_gemv_raw(int m, int n, double *c_matrix, double *x, double *y)
{
double one = 1.0;
double zero = 0.0;
bli_dgemv(BLIS_NO_TRANSPOSE, BLIS_NO_CONJUGATE,
m, n, &amp;amp;one, c_matrix, n, 1,
x, 1,
&amp;amp;zero,
y, 1);
}
&lt;/code>&lt;/pre>
&lt;/div>
&lt;p>To compile &lt;code>gemv_blis.c&lt;/code> into &lt;code>gemv_blis.o&lt;/code>, I used the following command, adapted from the PfHP course I mentioned earlier.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>gcc -c -O3 -m64 -mavx2 -std&lt;span style="color:#f92672">=&lt;/span>c99 -march&lt;span style="color:#f92672">=&lt;/span>native &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>-fopenmp -D_POSIX_C_SOURCE&lt;span style="color:#f92672">=&lt;/span>200809L -I/home/dhruv/blis/include/blis &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span>gemv_blis.c
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Note that though I am using &lt;code>-fopenmp&lt;/code>, I will not use multithreading, as multithreading is not much useful when we work with small data (as mentioned in the introduction.) For this, I will set &lt;code>OMP_NUM_THREADS=1&lt;/code>.&lt;/p>
&lt;p>The installed NumPy also had detected &lt;code>AVX2&lt;/code> support. So I will be doing a fair comparison. For those who do not know AVX2 or SIMD, SIMD stands for single instruction multiple data. SIMD is the reason why naive lowering to C would not have worked. When used properly, AVX2 instruction can execute floating points operations on 256 bits at a time. We can pack four fp64 numbers in 256 bits, so this would theoretically increase our performance by 4x. BLIS leverages AVX2.&lt;/p>
&lt;p>I am not writing the details for OpenBLAS wrapper and process of compiling it. If you are interested, please see &lt;code>Makefile&lt;/code> and &lt;code>gemv_openblas.c&lt;/code> files in the GitHub repository accompanying this post&lt;sup id="fnref:4">&lt;a href="#fn:4" class="footnote-ref" role="doc-noteref">4&lt;/a>&lt;/sup>.&lt;/p>
&lt;h3 id="step-3-writing-the-c-extension">Step 3: Writing the C extension.&lt;/h3>
&lt;p>We will need to call this wrapper function from Python. We can&amp;rsquo;t do that directly, as the wrapper expects pointers to raw memory. One alternative is to use &lt;code>ctypes&lt;/code>. I did try that, and converting NumPy arrays to appropriate pointers itself was taking more than the whole &lt;code>np.dot&lt;/code>. Instead, I am opting for writing a C extension to Python. I won&amp;rsquo;t be explaining the boilerplate code, please visit &lt;a href="https://docs.python.org/3/extending/extending.html">this link&lt;/a> which explains the process.&lt;/p>
&lt;div class="highlight">&lt;div style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;display:grid;">
&lt;table style="border-spacing:0;padding:0;margin:0;border:0;">&lt;tr>&lt;td style="vertical-align:top;padding:0;margin:0;border:0;">
&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;display:grid;">&lt;code>&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
&lt;/span>&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
&lt;/span>&lt;span style="background-color:#3c3d38">&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
&lt;/span>&lt;/span>&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
&lt;/span>&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
&lt;/span>&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
&lt;/span>&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
&lt;/span>&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
&lt;/span>&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
&lt;/span>&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
&lt;/span>&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
&lt;/span>&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
&lt;/span>&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
&lt;/span>&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
&lt;/span>&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
&lt;/span>&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
&lt;/span>&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
&lt;/span>&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18
&lt;/span>&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19
&lt;/span>&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">20
&lt;/span>&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">21
&lt;/span>&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">22
&lt;/span>&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">23
&lt;/span>&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">24
&lt;/span>&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">25
&lt;/span>&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">26
&lt;/span>&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">27
&lt;/span>&lt;span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">28
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;display:grid;">&lt;code class="language-c" data-lang="c">&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>...
&lt;/span>&lt;/span>&lt;span style="display:flex; background-color:#3c3d38">&lt;span>&lt;span style="color:#66d9ef">void&lt;/span> blis_gemv_raw(&lt;span style="color:#66d9ef">int&lt;/span> m, &lt;span style="color:#66d9ef">int&lt;/span> n, &lt;span style="color:#66d9ef">double&lt;/span> &lt;span style="color:#f92672">*&lt;/span>c_matrix, &lt;span style="color:#66d9ef">double&lt;/span> &lt;span style="color:#f92672">*&lt;/span>x, &lt;span style="color:#66d9ef">double&lt;/span> &lt;span style="color:#f92672">*&lt;/span>y);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">static&lt;/span> PyObject &lt;span style="color:#f92672">*&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>blis_dgemv(PyObject &lt;span style="color:#f92672">*&lt;/span>self, PyObject &lt;span style="color:#f92672">*&lt;/span>args)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">const&lt;/span> &lt;span style="color:#66d9ef">void&lt;/span> &lt;span style="color:#f92672">*&lt;/span>a;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Py_ssize_t asize;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Py_buffer in_buf, out_buf;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> in_buf.buf &lt;span style="color:#f92672">=&lt;/span> out_buf.buf &lt;span style="color:#f92672">=&lt;/span> NULL;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> in_buf.len &lt;span style="color:#f92672">=&lt;/span> out_buf.len &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">0&lt;/span>;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> (&lt;span style="color:#f92672">!&lt;/span>PyArg_ParseTuple(args, &lt;span style="color:#e6db74">&amp;#34;s#s*s*&amp;#34;&lt;/span>, &lt;span style="color:#f92672">&amp;amp;&lt;/span>a, &lt;span style="color:#f92672">&amp;amp;&lt;/span>asize, &lt;span style="color:#f92672">&amp;amp;&lt;/span>in_buf, &lt;span style="color:#f92672">&amp;amp;&lt;/span>out_buf)) {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> (in_buf.buf) PyBuffer_Release(&lt;span style="color:#f92672">&amp;amp;&lt;/span>in_buf);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> (out_buf.buf) PyBuffer_Release(&lt;span style="color:#f92672">&amp;amp;&lt;/span>out_buf);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> NULL;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">int&lt;/span> m, n;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> m &lt;span style="color:#f92672">=&lt;/span> out_buf.len&lt;span style="color:#f92672">/&lt;/span>&lt;span style="color:#66d9ef">sizeof&lt;/span>(&lt;span style="color:#66d9ef">double&lt;/span>);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> n &lt;span style="color:#f92672">=&lt;/span> in_buf.len&lt;span style="color:#f92672">/&lt;/span>&lt;span style="color:#66d9ef">sizeof&lt;/span>(&lt;span style="color:#66d9ef">double&lt;/span>);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> blis_gemv_raw(m, n, a, in_buf.buf, out_buf.buf);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Py_RETURN_NONE;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>In line 3, I declare the signature for &lt;code>blis_gemv_raw&lt;/code> defined and now residing in &lt;code>gemv_blis.o&lt;/code>. Next, I define a new function called &lt;code>blis_gemv&lt;/code>. This function will be called from Python with three arguments, namely matrix A, vector x, and vector y. I&amp;rsquo;m calling x as in_buf and y as out_buf. Once this parsing is successful, I compute m and n. m is computed using y and n is computed using x. Once I have all the arguments, I just call the wrapper around &lt;code>bli_dgemv&lt;/code>.&lt;/p>
&lt;h3 id="step-4-compiling-the-c-extension">Step 4: Compiling the C extension.&lt;/h3>
&lt;p>Finally, we need to create a shared object file that can be imported from Python. This is easy. Following is the &lt;code>setup.py&lt;/code> file.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> setuptools &lt;span style="color:#f92672">import&lt;/span> setup, Extension
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>module1 &lt;span style="color:#f92672">=&lt;/span> Extension(&lt;span style="color:#e6db74">&amp;#39;gemv&amp;#39;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> sources&lt;span style="color:#f92672">=&lt;/span>[&lt;span style="color:#e6db74">&amp;#39;gemvmodule.c&amp;#39;&lt;/span>],
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> extra_objects&lt;span style="color:#f92672">=&lt;/span>[&lt;span style="color:#e6db74">&amp;#39;gemv_blis.o&amp;#39;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#39;/home/dhruv/blis/lib/libblis.a&amp;#39;&lt;/span>],
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> libraries&lt;span style="color:#f92672">=&lt;/span>[&lt;span style="color:#e6db74">&amp;#39;m&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;pthread&amp;#39;&lt;/span>],
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> extra_compile_args&lt;span style="color:#f92672">=&lt;/span>[&lt;span style="color:#e6db74">&amp;#39;-fopenmp&amp;#39;&lt;/span>],
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> extra_link_args&lt;span style="color:#f92672">=&lt;/span>[&lt;span style="color:#e6db74">&amp;#39;-fopenmp&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;-m64&amp;#39;&lt;/span>])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>setup(name&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;gemv&amp;#39;&lt;/span>, version&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;0.1&amp;#39;&lt;/span>, ext_modules&lt;span style="color:#f92672">=&lt;/span>[module1])
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Generate the &lt;code>gemv.so&lt;/code> (or something similar, depending upon your OS), using the following command.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>python setup.py build_ext --inplace
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Et, voila! Now we can just &lt;code>import gemv&lt;/code> and call the &lt;code>gemv.blis_dgemv&lt;/code> with three appropriately shaped ndarrays.&lt;/p>
&lt;h2 id="benchmarking">Benchmarking&lt;/h2>
&lt;p>I ran both NumPy and BLIS based implementation on batches of [10, 50, 100, 500, 1000] for vector size of 128. Following are the results.&lt;/p>
&lt;p>&lt;img src="./benchmark.png" alt="benchmark_result.png">&lt;/p>
&lt;p>Following table shows percentage improvement over &lt;code>np.dot&lt;/code>. This was computed as $\frac{\text{numpy\_time} - \text{my\_time}}{\text{numpy\_time}}$.&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>batch_size&lt;/th>
&lt;th style="text-align:right">%improvement&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>10&lt;/td>
&lt;td style="text-align:right">25.75 %&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>50&lt;/td>
&lt;td style="text-align:right">26.21 %&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>100&lt;/td>
&lt;td style="text-align:right">24.07 %&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>500&lt;/td>
&lt;td style="text-align:right">11.06 %&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>1000&lt;/td>
&lt;td style="text-align:right">12.22 %&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="conclusion">Conclusion&lt;/h2>
&lt;p>For all the batch sizes, our implementation performs better than NumPy. When the batch size is ≤ 100, the improvements are around 25%. As the batch size increases, the percentage improvement decreases. This is expected, as more time would be taken by the computation instead of the overhead. Still, 10% is good! You can run the benchmark on your computer by running &lt;code>benchmark.py&lt;/code> from the GitHub repository.&lt;/p>
&lt;p>However, call me greedy if you want, but maybe there is still a scope for improvement? gemv is a general implementation. Maybe just for the pure dot product, we can strip some code out? Worth experimenting. I&amp;rsquo;ll write a new blog if I do that. Meanwhile, if you have any suggestions, or comments, please drop me an email at &lt;code>hello@dxxxxxxxxl.dev&lt;/code>.&lt;/p>
&lt;h2 id="references">References&lt;/h2>
&lt;div class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1">
&lt;p>&lt;a href="https://github.com/flame/blis/">https://github.com/flame/blis/&lt;/a>&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2">
&lt;p>&lt;a href="https://www.openblas.net/">https://www.openblas.net/&lt;/a>&amp;#160;&lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:3">
&lt;p>&lt;a href="https://github.com/flame/blis/blob/master/docs/BLISTypedAPI.md#gemv">https://github.com/flame/blis/blob/master/docs/BLISTypedAPI.md#gemv&lt;/a>&amp;#160;&lt;a href="#fnref:3" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:4">
&lt;p>&lt;a href="https://github.com/DhruvPatel01/notebooks/tree/main/High_Performance_Computing/mat_vec">https://github.com/DhruvPatel01/notebooks/tree/main/High_Performance_Computing/mat_vec&lt;/a>&amp;#160;&lt;a href="#fnref:4" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div></content></item><item><title>Why the solution to part 2(AoC21-Day7) works?</title><link>https://dhruvpatel.dev/posts/aoc/21/day7/</link><pubDate>Tue, 07 Dec 2021 16:28:35 +0530</pubDate><guid>https://dhruvpatel.dev/posts/aoc/21/day7/</guid><description>Problem We are given an array of integers, $x_1, x_2, \dots, x_N.$ We want to find an $x$ (also an integer) that minimizes some cost function.
$$ argmin_x \sum_{i=1}^N f(x_i, x) $$
Part 1 has a simple cost function, L1 distance. i.e. $f(x_i, x) = | x_i - x|$. Even with non-differentiability, there is a closed form solution to this function, a median. The proofs are there on the Internet, or the book Probability and Computing[1].</description><content>&lt;h2 id="problem">Problem&lt;/h2>
&lt;p>We are given an array of integers, $x_1, x_2, \dots, x_N.$ We want to find an $x$ (also an integer) that minimizes some cost function.&lt;/p>
&lt;p>$$
argmin_x \sum_{i=1}^N f(x_i, x)
$$&lt;/p>
&lt;p>Part 1 has a simple cost function, L1 distance. i.e. $f(x_i, x) = | x_i - x|$. Even with non-differentiability, there is a closed form solution to this function, a median. The proofs are there on the Internet, or the book Probability and Computing[1].&lt;/p>
&lt;p>Part 2 has a non-trivial cost function. If L1 between $x_i$ and $x$ is $d$, the cost function $f$ is defined as $f(x_i, x) = \sum_{i=1}^d i = \frac{d(d+1)}{2} \propto d^2+d.$ This cost function is deceptively similar to L2 (or L1)!&lt;/p>
&lt;p>&lt;strong>Note:&lt;/strong> The code snippets and values in this blog are from input generated for me. I think Advent of Code generates different inputs for different people. So, you might not be able to replicate exact numbers here, but direction should be same.&lt;/p>
&lt;h2 id="first-approach-to-the-solution">First approach to the solution.&lt;/h2>
&lt;p>At first, I thought, this is some kind of combination of L1 and L2. Both L1 and L2 cost functions have a closed form solution (median and mean, respectively). Surely, this one has one too. After all, we are at day 7 only! I pulled pen and paper out, and started differentiating.&lt;/p>
&lt;p>$$
\begin{aligned}
L(X, x) &amp;amp;= \sum_{i=1}^N f(x_i, x) \\
&amp;amp;= \sum_{i=1}^N (x_i - x)^2 + |x_i - x| \\
&amp;amp;= \sum_{i=1}^N (x_i^2 + x^2 - 2x_ix) + | x_i - x| \\
\end{aligned}
$$&lt;/p>
&lt;p>$$
\begin{aligned}
\frac{d L(X, x)}{dx} &amp;amp;= \sum_{i=1}^N (2x - 2x_i) + sign(| x_i - x|) \\
&amp;amp;= 2Nx - 2\sum_{i=1}^N x_i + \sum_{i=1}^N sign(| x_i - x|)
= 0\end{aligned}
$$&lt;/p>
&lt;p>I got stuck here. How do I write above thing in the form $x = $ something?&lt;/p>
&lt;h2 id="second-approach">Second approach&lt;/h2>
&lt;p>After banging my head for some time, I changed the approach. It is obvious that the loss function is convex. It is a sum of quadratics and linear terms, each of them is convex. Sum of convex functions is convex. So a unique global minimum exists. But how do I find it in a closed form? Not all convex problems have closed form solutions, e.g. Logistic Regression.&lt;/p>
&lt;p>Also, the solution $x$ has to lie between min(x) and max(x). Obviously! Maybe I can find answer visually?&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">cost&lt;/span>(X, x):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> d &lt;span style="color:#f92672">=&lt;/span> np&lt;span style="color:#f92672">.&lt;/span>abs(X&lt;span style="color:#f92672">-&lt;/span>x)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> d&lt;span style="color:#f92672">*&lt;/span>(d&lt;span style="color:#f92672">+&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>)&lt;span style="color:#f92672">/&lt;/span>&lt;span style="color:#ae81ff">2&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>s &lt;span style="color:#f92672">=&lt;/span> np&lt;span style="color:#f92672">.&lt;/span>linspace(X&lt;span style="color:#f92672">.&lt;/span>min(), X&lt;span style="color:#f92672">.&lt;/span>max(), &lt;span style="color:#ae81ff">10000&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>costs &lt;span style="color:#f92672">=&lt;/span> [cost(X, x)&lt;span style="color:#f92672">.&lt;/span>sum() &lt;span style="color:#66d9ef">for&lt;/span> x &lt;span style="color:#f92672">in&lt;/span> s]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>argmin &lt;span style="color:#f92672">=&lt;/span> np&lt;span style="color:#f92672">.&lt;/span>argmin(costs)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Following is the output plotted.&lt;/p>
&lt;p>&lt;img src="images/day7_plot.png" alt="plot">&lt;/p>
&lt;p>&lt;code>s[argmin]&lt;/code> gave me &lt;code>482.555&lt;/code>. Since required answer is integer and function is convex, I computed the cost of 482 and 483, and &lt;code>cost(X, 482) &amp;lt; cost(X, 483)&lt;/code>. And, that indeed, was the correct answer.&lt;/p>
&lt;h2 id="ok-so-what">Ok, so what?&lt;/h2>
&lt;p>Nothing exceptional has happened so far. I could have just used binary search, or could have called heavy guns like PyTorch or JAX to do the optimization.&lt;/p>
&lt;p>The thing that surprised me was the statement &lt;code>print(X.mean())&lt;/code>. This printed &lt;code>482.59&lt;/code>. The mean is very close to the answer I got using Grid Search! How can I be sure if the mean is not the optimizer? But how can that be? Mean is the optimizer of the L2 loss function. Is this just a coincidence? Many people indeed came up with the solution by just computing the mean instead of doing a grid search. And it works!&lt;/p>
&lt;p>To explain why this would work, let&amp;rsquo;s revisit the derivation. This time I will write it differently, so that I don&amp;rsquo;t need to worry about undefined differentiation at some points.&lt;/p>
&lt;p>$$
\begin{aligned}
L(X, x) &amp;amp;=
\sum_{i \; | \; x_i \, \le \, x} f(x_i, x) + \sum_{i \; | \; x_i \,&amp;gt; \,x} f(x_i, x) \\
&amp;amp;= \sum_{i \; | \; x_i \, \le \, x} (x_i - x)^2 + x-x_i +
\sum_{i \; | \; x_i \,&amp;gt; \,x} (x_i - x)^2 + x_i - x \\
&amp;amp;= \sum_{i=1}^N (x_i^2 + x^2 - 2x_ix) +
\sum_{i \; | \; x_i \, \le \, x} x-x_i +
\sum_{i \; | \; x_i \,&amp;gt; \,x} x_i - x \\
\end{aligned}
$$&lt;/p>
&lt;p>Now, this function is differentiable at all points.&lt;/p>
&lt;p>$$
\begin{align*}
\frac{d L(X, x)}{dx} &amp;amp;= \sum_{i=1}^N (2x - 2x_i) +
\sum_{i \; | \; x_i \, \le \, x} 1 +
\sum_{i \; | \; x_i \, &amp;gt; \, x} -1 \\
&amp;amp;= 2Nx - 2\sum_{i=1}^N x_i + N_{\le} - N_{&amp;gt;} = 0
\end{align*}
$$&lt;/p>
&lt;p>Here, I have defined $N_{\le}$ to be the number of elements less than or equal to $x$, and similarly $N_&amp;gt;$&lt;/p>
&lt;p>$$
\begin{align*}
x &amp;amp;= \frac{2\sum_{i=1}^N x_i + N_&amp;gt; - N_\le}{2N} \\
&amp;amp;= \bar{x} + \frac{1}{2} \frac{N_&amp;gt; - N_\le}{N}
\end{align*}
$$&lt;/p>
&lt;p>We do not know the values of $N_&amp;gt;$ and $N_\le$. But, we can get bounds by doing worse case analysis.&lt;/p>
&lt;p>In one case, $N_&amp;gt; = 0, N_\le = N$, which gives us $x \ge \bar{x} - \frac{1}{2}$. On other extreme, $N_&amp;gt; = N, N_\le = 0$, which gives us $x \le \bar{x} + \frac{1}{2}$.&lt;/p>
&lt;p>So, $\bar{x} - \frac{1}{2} \le x \le \bar{x} + \frac{1}{2}$. This is the reason why looking at integers near to $\bar{x}$ as candidate solutions, was the correct thing to do.&lt;/p>
&lt;h2 id="references">References&lt;/h2>
&lt;ol>
&lt;li>Mitzenmacher, Michael, and Eli Upfal. Probability and computing: Randomization and probabilistic techniques in algorithms and data analysis. Cambridge university press, 2017. (Chapter 3)&lt;/li>
&lt;/ol></content></item><item><title>Why Blelloch Scan Works</title><link>https://dhruvpatel.dev/posts/why_blelloch_scan_works/</link><pubDate>Sat, 02 Oct 2021 09:31:44 +0530</pubDate><guid>https://dhruvpatel.dev/posts/why_blelloch_scan_works/</guid><description>Blelloch scan is a (exclusive) scan algorithm for parallel computers. A common example of scan is prefix sum.
python sequential.py def exclusive_scan(a, op): b = [0] # Identity of the op, (for sum and max, it is 0). for x in a[:-1]: b.append(op(x, b[-1])) return b exclusive_scan([1, 2, 3, 4], lambda x, y: x&amp;#43;y) == [0, 1, 3, 6] exclusive_scan([1, 2, 3, 4], max) == [0, 1, 2, 3] This vlog is complementary to the excellent video description from now archived Udacity CS344 course.</description><content>&lt;p>Blelloch scan is a (exclusive) scan algorithm for parallel computers. A common example of scan is prefix sum.&lt;/p>
&lt;div class="collapsable-code">
&lt;input id="473512869" type="checkbox" />
&lt;label for="473512869">
&lt;span class="collapsable-code__language">python&lt;/span>
&lt;span class="collapsable-code__title">sequential.py&lt;/span>
&lt;span class="collapsable-code__toggle" data-label-expand="△" data-label-collapse="▽">&lt;/span>
&lt;/label>
&lt;pre class="language-python" >&lt;code>
def exclusive_scan(a, op):
b = [0] # Identity of the op, (for sum and max, it is 0).
for x in a[:-1]:
b.append(op(x, b[-1]))
return b
exclusive_scan([1, 2, 3, 4], lambda x, y: x&amp;#43;y) == [0, 1, 3, 6]
exclusive_scan([1, 2, 3, 4], max) == [0, 1, 2, 3]
&lt;/code>&lt;/pre>
&lt;/div>
&lt;p>This vlog is complementary to the excellent &lt;a href="https://youtu.be/mmYv3Haj6uc">video description&lt;/a> from now archived Udacity CS344 course. The video explains the &amp;ldquo;how&amp;rdquo; of the algorithm very well, but I couldn&amp;rsquo;t easily find &amp;ldquo;why&amp;rdquo; of the algorithm, neither in that video nor in any other videos on the Internet. So here is my attempt to explain it.&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/04QXOwzdIOg" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div></content></item><item><title>Python got me with circular imports!</title><link>https://dhruvpatel.dev/posts/python_circular_imports/</link><pubDate>Wed, 14 Apr 2021 21:51:48 +0530</pubDate><guid>https://dhruvpatel.dev/posts/python_circular_imports/</guid><description>I have been programming in Python from last seven years. Apart from the new features Python adds in every new release, I didn&amp;rsquo;t think Python would surprise me, until it did.
I will demonstrate what happened with the trimmed down code. I have two files, main.py and notmain.py. main.py has a global variable called var. notmain has some code that would process user input and add entry into main.var. Pretty simple, right?</description><content>&lt;p>I have been programming in Python from last seven years. Apart from the new features Python adds in every new release, I didn&amp;rsquo;t think Python would surprise me, until it did.&lt;/p>
&lt;p>I will demonstrate what happened with the trimmed down code. I have two files, &lt;code>main.py&lt;/code> and &lt;code>notmain.py&lt;/code>. &lt;code>main.py&lt;/code> has a global variable called &lt;code>var&lt;/code>. &lt;code>notmain&lt;/code> has some code that would process user input and add entry into &lt;code>main.var&lt;/code>. Pretty simple, right?&lt;/p>
&lt;div class="collapsable-code">
&lt;input id="942375618" type="checkbox" />
&lt;label for="942375618">
&lt;span class="collapsable-code__language">python&lt;/span>
&lt;span class="collapsable-code__title">main.py&lt;/span>
&lt;span class="collapsable-code__toggle" data-label-expand="Hide" data-label-collapse="Hide">&lt;/span>
&lt;/label>
&lt;pre class="language-python" >&lt;code>
import notmain
var = {}
def work():
print(&amp;#34;Before:&amp;#34;, var)
notmain.populate()
print(&amp;#34;After: &amp;#34;, var)
if __name__ == &amp;#39;__main__&amp;#39;:
work()
&lt;/code>&lt;/pre>
&lt;/div>
&lt;div class="collapsable-code">
&lt;input id="659721348" type="checkbox" />
&lt;label for="659721348">
&lt;span class="collapsable-code__language">python&lt;/span>
&lt;span class="collapsable-code__title">notmain.py&lt;/span>
&lt;span class="collapsable-code__toggle" data-label-expand="Hide" data-label-collapse="Hide">&lt;/span>
&lt;/label>
&lt;pre class="language-python" >&lt;code>
import main
def populate():
main.var[&amp;#39;answer&amp;#39;] = 42
&lt;/code>&lt;/pre>
&lt;/div>
&lt;p>What do you think will happen when I run &lt;code>python main.py&lt;/code>? Don&amp;rsquo;t know about you, but I imagined that after I call &lt;code>notmain.populate&lt;/code>, &lt;code>main.var&lt;/code> will have one key, value in it.&lt;/p>
&lt;pre tabindex="0">&lt;code>Shell&amp;gt; python main.py
Before: {}
After: {}
&lt;/code>&lt;/pre>&lt;p>But boy I was wrong. To explain what just happened, let me try to explain how Python imports work.&lt;/p>
&lt;h2 id="how-does-python-import-work-a-simple-version">How does Python import work? (A simple version)&lt;/h2>
&lt;p>In what follows, I only explain what happens when you use &lt;code>import x&lt;/code>. &lt;code>from x import y&lt;/code> is not explained here.&lt;/p>
&lt;p>When you import a module, two steps happen.&lt;/p>
&lt;ol>
&lt;li>Search (done by finder)&lt;/li>
&lt;li>Load (done by loader)&lt;/li>
&lt;/ol>
&lt;p>In the search step, &lt;code>sys.modules&lt;/code> is the first place checked. If the module is not in &lt;code>sys.modules&lt;/code>, Python will search for that module in other ways, current directory being one of them. Once the module(which was not in &lt;code>sys.modules&lt;/code>) is found, it will be added to &lt;code>sys.modules&lt;/code> before step 2 is executed. Thus if &lt;code>a&lt;/code> imports &lt;code>b&lt;/code>, and &lt;code>b&lt;/code> imports &lt;code>c&lt;/code>, and &lt;code>c&lt;/code> imports &lt;code>b&lt;/code>, &lt;code>b&lt;/code> will not be executed again.&lt;/p>
&lt;p>If the module was not found in &lt;code>sys.modules&lt;/code>, the loading step will execute the module and the exported variables will be made available in the importee module.&lt;/p>
&lt;p>One thing you should note is that everything in Python is an object. Even the imported module is. Try this,&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> math&lt;span style="color:#f92672">,&lt;/span> types
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">assert&lt;/span> isinstance(math, types&lt;span style="color:#f92672">.&lt;/span>ModuleType)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Objects are stored somewhere in memory. Try this,&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>print(hex(id(math)))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># printed &amp;#39;0x7f7e21029c20&amp;#39; on my machine&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>So everything in the object module will be available as attributes.&lt;/p>
&lt;p>Now that we know how import works, let&amp;rsquo;s try to see what happened with my code.&lt;/p>
&lt;h2 id="what-happened-with-my-code">What happened with my code?&lt;/h2>
&lt;p>Let&amp;rsquo;s augment the files to print location of &lt;code>var&lt;/code> object. That shall give some ideas.&lt;/p>
&lt;div class="collapsable-code">
&lt;input id="867453912" type="checkbox" />
&lt;label for="867453912">
&lt;span class="collapsable-code__language">python&lt;/span>
&lt;span class="collapsable-code__title">main.py&lt;/span>
&lt;span class="collapsable-code__toggle" data-label-expand="Hide" data-label-collapse="Hide">&lt;/span>
&lt;/label>
&lt;pre class="language-python" >&lt;code>
import notmain
var = {}
print(&amp;#34;In Main: &amp;#34;, hex(id(var)))
def work():
print(&amp;#34;Before:&amp;#34;, var, &amp;#39;at&amp;#39;, hex(id(var)))
notmain.populate()
print(&amp;#34;After: &amp;#34;, var, &amp;#39;at&amp;#39;, hex(id(var)))
if __name__ == &amp;#39;__main__&amp;#39;:
work()
&lt;/code>&lt;/pre>
&lt;/div>
&lt;div class="collapsable-code">
&lt;input id="394576218" type="checkbox" />
&lt;label for="394576218">
&lt;span class="collapsable-code__language">python&lt;/span>
&lt;span class="collapsable-code__title">notmain.py&lt;/span>
&lt;span class="collapsable-code__toggle" data-label-expand="Hide" data-label-collapse="Hide">&lt;/span>
&lt;/label>
&lt;pre class="language-python" >&lt;code>
import main
def populate():
main.var[&amp;#39;answer&amp;#39;] = 42
print(&amp;#39;In not main: &amp;#39;, main.var, &amp;#39;at&amp;#39;, hex(id(main.var)))
&lt;/code>&lt;/pre>
&lt;/div>
&lt;pre tabindex="0">&lt;code>Shell&amp;gt; python main.py
In Main: 0x7f64e4778cc0
In Main: 0x7f64e490c6c0
Before: {} at 0x7f64e490c6c0
In not main: {&amp;#39;answer&amp;#39;: 42} at 0x7f64e4778cc0
After: {} at 0x7f64e490c6c0
&lt;/code>&lt;/pre>&lt;p>First of all notice that &lt;code>In Main: ...&lt;/code> line is printed two times. In the previous section I did tell that &lt;strong>if the module is found in &lt;code>sys.modules&lt;/code>&lt;/strong>, the module will not be executed again. The problem is that &lt;code>main.py&lt;/code> is only imported once, but executed twice.&lt;/p>
&lt;p>Here is what happens.&lt;/p>
&lt;ul>
&lt;li>&lt;code>python main.py&lt;/code> starts executing.&lt;/li>
&lt;li>The first line is &lt;code>import notmain&lt;/code>. Since &lt;code>notmain&lt;/code> is not in &lt;code>sys.modules&lt;/code> yet, it will be executed next. Notice that &lt;code>main&lt;/code> was never imported. So &lt;code>sys.modules&lt;/code> does not have an entry for &lt;code>main&lt;/code>.&lt;/li>
&lt;li>Control goes to &lt;code>notmain.py&lt;/code>. First line of it is &lt;code>import main&lt;/code>, and as &lt;code>main&lt;/code> is not in the cache, finder adds it into &lt;code>sys.modules&lt;/code> and then loader starts executing &lt;code>main.py&lt;/code> (again!).&lt;/li>
&lt;li>Control goes to &lt;code>main.py&lt;/code>. Since the first line is &lt;code>import notmain&lt;/code> and &lt;code>notmain&lt;/code> &lt;strong>is in&lt;/strong> the &lt;code>sys.modules&lt;/code> now, there is no effect.&lt;/li>
&lt;li>Next line in &lt;code>main.py&lt;/code> creates a variable &lt;code>var@0x7f64e4778cc0&lt;/code>.&lt;/li>
&lt;li>Next few lines defines a function &lt;code>work&lt;/code>.&lt;/li>
&lt;li>The &lt;code>__name__ == '__main__'&lt;/code> condition is false, as at the moment &lt;code>__name__ == 'main'&lt;/code>&lt;/li>
&lt;li>Control goes back to &lt;code>notmain.py&lt;/code>. Attributes from the &lt;code>main&lt;/code> module will now be accessible.&lt;/li>
&lt;li>&lt;code>populate&lt;/code> is defined in &lt;code>notmain&lt;/code>.&lt;/li>
&lt;li>Control comes back to &lt;code>main&lt;/code>.&lt;/li>
&lt;li>Variable &lt;code>var&lt;/code> is created (again!) and stored at &lt;code>0x7f64e490c6c0&lt;/code>. Notice that there are two &lt;code>var&lt;/code> variables. &lt;code>notmain&lt;/code> has no idea that there is another &lt;code>var&lt;/code> at &lt;code>0x7f64e490c6c0&lt;/code>, it still thinks that &lt;code>main.var&lt;/code> is at &lt;code>0x7f64e4778cc0&lt;/code>.&lt;/li>
&lt;li>&lt;code>work&lt;/code> function is defined.&lt;/li>
&lt;li>&lt;code>__name__ == '__main__'&lt;/code> condition evaluates to true this time. So &lt;code>work&lt;/code> is called, which calls &lt;code>notmain.populate&lt;/code>.&lt;/li>
&lt;li>&lt;code>notmain.populate&lt;/code> adds &lt;code>answer&lt;/code> key into &lt;code>main.var&lt;/code> and not &lt;code>__main__.var&lt;/code>.&lt;/li>
&lt;/ul>
&lt;p>The issue is self-evident now. We need to distinguish between &lt;code>main&lt;/code> and &lt;code>__main__&lt;/code>. A simple solution is to create another file that imports &lt;code>main&lt;/code> and then calls &lt;code>main.work&lt;/code>. This way when &lt;code>notmain&lt;/code> calls import, &lt;code>sys.modules&lt;/code> will already have an entry for &lt;code>main&lt;/code> and &lt;code>main&lt;/code> will not be executed again, and both &lt;code>main&lt;/code> and &lt;code>notmain&lt;/code> have same view of &lt;code>var&lt;/code>. So let&amp;rsquo;s try this.&lt;/p>
&lt;div class="collapsable-code">
&lt;input id="581924736" type="checkbox" />
&lt;label for="581924736">
&lt;span class="collapsable-code__language">python&lt;/span>
&lt;span class="collapsable-code__title">really_main.py&lt;/span>
&lt;span class="collapsable-code__toggle" data-label-expand="△" data-label-collapse="▽">&lt;/span>
&lt;/label>
&lt;pre class="language-python" >&lt;code>
import main
main.work()
# no change in other files
&lt;/code>&lt;/pre>
&lt;/div>
&lt;pre tabindex="0">&lt;code>Shell&amp;gt; python really_main.py
Before: {}
After: {&amp;#39;answer&amp;#39;: 42}
&lt;/code>&lt;/pre>&lt;p>Whooo! That worked.&lt;/p>
&lt;h2 id="comments">Comments?&lt;/h2>
&lt;p>You have any doubts? Any feedbacks? Please reach out to me at &lt;code>hello at domain&lt;/code> with subject line &lt;code>Comment: Post title&lt;/code>. I&amp;rsquo;ll get back to you as soon as possible.&lt;/p></content></item><item><title>NotAeroCalc Part 1: What is NotAeroCalc and how to use it?</title><link>https://dhruvpatel.dev/posts/notaerocalc/notaerocalc_part1/</link><pubDate>Sat, 03 Apr 2021 18:04:02 +0530</pubDate><guid>https://dhruvpatel.dev/posts/notaerocalc/notaerocalc_part1/</guid><description>I am a Computer Engineer by education and by training. Luckily, we computer engineers do not have to deal with different units. All our units are power of 2. We have sensible names, Kilo, Mega, Giga, you get it. When we get unlucky, there could be a confusion of whether Kilo in the context is $ 2^{10} $ or $ 10^3 $. But that is it.
But in other engineering (and science) branches this is not the case.</description><content>&lt;p>I am a Computer Engineer by education and by training. Luckily, we computer engineers do not have to deal with different units. All our units are power of 2. We have sensible names, Kilo, Mega, Giga, you get it. When we get unlucky, there could be a confusion of whether Kilo in the context is $ 2^{10} $ or $ 10^3 $. But that is it.&lt;/p>
&lt;p>But in other engineering (and science) branches this is not the case. A while ago I was taking a course &amp;ldquo;Introduction Aeronautical Engineering&amp;rdquo; on edX (the course is from TUDelft). Honestly, the homework problems there were annoying, at least for me. I can understand that students in the Aero department might need to practice the conversion process.&lt;/p>
&lt;p>There is a &lt;code>Newton&lt;/code>, which is also $\frac{kg * m}{s^2}$. There is an imperial unit for length called &lt;code>foot&lt;/code>, but you &lt;strong>have to&lt;/strong> convert that into SI units to be compatible with other units in the formula, because the constants in the formula use &lt;code>m&lt;/code>. Then there is &lt;code>Celsius&lt;/code> to &lt;code>Kelvin&lt;/code> mapping. You either have to memorize the conversion factors, or you have to make a long list of the conversion factors.&lt;/p>
&lt;p>Something had to be done. And I was also looking for something to do on the weekends. So I am working on &lt;a href="https://github.com/DhruvPatel01/NotAeroCalc/">NotAeroCalc&lt;/a>. I kept Aero in because my primary aim is to expedite solving homework problems in that course. But many parts of the app are general and should be usable outside Aerospace engineering.&lt;/p>
&lt;p>Rather than explaining what NotAeroCalc does, let me show you it in action.&lt;/p>
&lt;script id="asciicast-sYPyE91MGr9QOamVwnYThzlZN" src="https://asciinema.org/a/sYPyE91MGr9QOamVwnYThzlZN.js" async>&lt;/script>
&lt;p>You might have noticed a few things. First there is a need for &lt;code>*&lt;/code> between quantity and its unit. I designed it this way because it simplifies the grammar. Another thing is that units are not pluralized, e.g. it is &lt;code>32000 foot&lt;/code> and not &lt;code>32000 feet&lt;/code>. If you need your answer in SI units just use &lt;code>expression in si&lt;/code>.&lt;/p>
&lt;p>In the backend I am using an amazing Python library called &lt;a href="https://www.astropy.org/">Astropy&lt;/a> for conversion and &lt;a href="https://github.com/dabeaz/ply">Ply&lt;/a> for parsing. You can use all the units available in Astropy, the list can be found &lt;a href="https://docs.astropy.org/en/stable/units/">here&lt;/a>.&lt;/p>
&lt;p>You can also use math constants like &lt;code>pi&lt;/code> and &lt;code>e&lt;/code>. Internally NotAeroCalc looks for unresolved names in &lt;code>math&lt;/code> library in Python. So if you haven&amp;rsquo;t created a &lt;code>pi&lt;/code> variable, &lt;code>math.pi&lt;/code> will be used.&lt;/p>
&lt;h2 id="commands-in-notaerocalc">Commands in NotAeroCalc&lt;/h2>
&lt;dl>
&lt;dt>&lt;code>del x&lt;/code>&lt;/dt>
&lt;dd>deletes the variable named &lt;code>x&lt;/code> if defined. If not defined ignores the command.&lt;/dd>
&lt;dt>&lt;code>variables&lt;/code>&lt;/dt>
&lt;dd>lists all the variables defined in the current session.&lt;/dd>
&lt;/dl>
&lt;h2 id="problem-solving-with-notaerocalc">Problem Solving with NotAeroCalc&lt;/h2>
&lt;p>Let&amp;rsquo;s try to solve one problem using NotAeroCalc. Below is one of the homework problems from the course.&lt;/p>
&lt;pre tabindex="0">&lt;code>An aircraft flies at an altitude of 30,000 feet.
Determine the air temperature (in [K]),
air pressure (in [Pa]) and air density (in [kg/m3])
at this altitude, according to the standard atmosphere.
&lt;/code>&lt;/pre>&lt;p>Following are the variables given.&lt;/p>
&lt;pre tabindex="0">&lt;code>g = 9.80665 * m/s/s
T0 = 15*Celsius in Kelvin
P0 = 1013.25 * hectopascal
h = 30000 * foot in m
a = -6.5 * Kelvin/km
rho0 = 1.225 * kg/m^3
&lt;/code>&lt;/pre>&lt;p>Notice that some variables are given in &lt;code>m&lt;/code> whereas others are in &lt;code>km&lt;/code>. A good thing about using NotAeroCalc is that generally you do not need to worry about this discrepancy. However you can always use &lt;code>expr in si&lt;/code> to have unified values.&lt;/p>
&lt;p>Since 30,000 foot is in troposphere, we can use $ T_1 = T_0 + a*h $ formula to compute the temperature at 32000 foot.&lt;/p>
&lt;p>Once we know the temperature, we can use the following formula to compute the air density.&lt;/p>
&lt;p>$$
\frac{\rho_0}{\rho_1} = {\left( \frac{T_1}{T_0} \right)} ^{\frac{g}{R * a} - 1}
$$&lt;/p>
&lt;p>There are few things about &lt;code>^&lt;/code> operator in NotAeroCalc that you should keep in mind.&lt;/p>
&lt;ul>
&lt;li>In &lt;code>a^b&lt;/code>, &lt;code>b&lt;/code> has to be unit less. So expression like &lt;code>2^(3*m/(3*m))&lt;/code> is allowed, but &lt;code>2^(3*m/3*m)&lt;/code> is not, as it simplifies to &lt;code>2^(1*m^2)&lt;/code>.&lt;/li>
&lt;li>By default the units are not simplified, you might have to use &lt;code>a^(b in si)&lt;/code> if units in b cancel out.&lt;/li>
&lt;li>&lt;code>2^((3*m)/(300*cm))&lt;/code> will give you an error. Use &lt;code>2^((3*m)/(300*cm) in si)&lt;/code> for now. I might fix this later.&lt;/li>
&lt;li>If &lt;code>a&lt;/code> has units, &lt;code>b&lt;/code> has to be like an integer. &lt;code>b = 3.0&lt;/code> is allowed, but &lt;code>b = 3.14&lt;/code> is not. So &lt;code>(3*m)^2.0&lt;/code> evaluates to &lt;code>9*m^2&lt;/code>.&lt;/li>
&lt;li>Finally, if &lt;code>a&lt;/code> does not have units, any power is allowed.&lt;/li>
&lt;/ul>
&lt;p>In the above density formula, the exponent is actually unit less. So everything works out.&lt;/p>
&lt;p>See the following recording for the whole solution.&lt;/p>
&lt;script id="asciicast-oTGxU3t8WOPyI6orh3W0TBMfh" src="https://asciinema.org/a/oTGxU3t8WOPyI6orh3W0TBMfh.js" async>&lt;/script>
&lt;h2 id="what-is-next">What is next?&lt;/h2>
&lt;p>As far as blogging goes, I plan to write the details of how NotAeroCalc was implemented, the nitty gritty details of Lex and Yacc, in the next part. It is not that difficult really.&lt;/p>
&lt;p>In the NotAeroCalc itself, I plan to add some features like having a database of formulas, and solving for a particular variables using other user defined variables.&lt;/p>
&lt;p>GitHub repository for this project can be found &lt;a href="https://github.com/DhruvPatel01/NotAeroCalc/">here&lt;/a>.&lt;/p></content></item><item><title>How to find the number of unique elements in a stream?</title><link>https://dhruvpatel.dev/posts/flajolet-martin/</link><pubDate>Mon, 29 Mar 2021 14:36:16 +0530</pubDate><guid>https://dhruvpatel.dev/posts/flajolet-martin/</guid><description>So, I&amp;rsquo;ve been reading about streaming algorithms. Seems like the journey to streaming algorithms(aka Algorithms for Big Data) starts with the Flajolet-Martin algorithm.
The Problem We are given a sequence &amp;lt;u_0, u_1, u_2, u_3, ... , u_n&amp;gt; of n elements. Each u_i comes from the fixed set U of some finite size. We want to see how many elements are unique.
A simple Python code like below can solve the problem, if we have required memory.</description><content>&lt;p>So, I&amp;rsquo;ve been reading about streaming algorithms. Seems like the journey to streaming algorithms(aka Algorithms for Big Data) starts with the Flajolet-Martin algorithm.&lt;/p>
&lt;h2 id="the-problem">The Problem&lt;/h2>
&lt;p>We are given a sequence &lt;code>&amp;lt;u_0, u_1, u_2, u_3, ... , u_n&amp;gt;&lt;/code> of &lt;code>n&lt;/code> elements. Each &lt;code>u_i&lt;/code> comes from the fixed set &lt;code>U&lt;/code> of some finite size. We want to see how many elements are unique.&lt;/p>
&lt;p>A simple Python code like below can solve the problem, if we have required memory.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">card&lt;/span>(seq):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> len(set(seq))
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>But we might not have a required memory. Hence we need to make a tradeoff. Use little memory and get an approximate answer or use &lt;code>O(|U|)&lt;/code> memory, and get the accurate answer. We will go with a small memory.&lt;/p>
&lt;h2 id="flajolet-martin-algorithm-a-handwavy-explanation">Flajolet-Martin Algorithm (a handwavy explanation)&lt;/h2>
&lt;p>The idea behind the FM algorithm is that each element generates an event. Same element has the same event associated with it. So if &lt;code>x_2 == x&lt;/code> generates &lt;code>blahblah&lt;/code>, and &lt;code>x_100 == x&lt;/code>, &lt;code>blahblah&lt;/code> will be generated. Summary is that you look for an event that is rare. Now if the events are generated from uniform distribution, as we see more and more &amp;ldquo;rare&amp;rdquo; events, we can be confident that we have seen &amp;ldquo;more&amp;rdquo; unique elements.&lt;/p>
&lt;p>Let me give an example. Say our event is the number of trailing zeros of the hash of the incoming element. So if the hash is &lt;code>101010&lt;/code>, the trail length is 1. On average how many different hashes would you have to see to see a trail length of 1? It&amp;rsquo;s a coin toss, on average you would have to toss a coin twice to get Heads. What if we wanted 5 heads and 1 tail? You would have to toss a coin 64 times to see that event.&lt;/p>
&lt;p>Wikipedia, Chapter-4 of Mining Massive Datasets, an original paper, and numerous other blogs describe this algorithm, so I won&amp;rsquo;t. I tried to implement this algorithm using the trail length as an event, but even with using 1000 hash functions I wasn&amp;rsquo;t able to get a reasonably close answer. So I will describe and implement what I believe is a better version of the same algorithm.&lt;/p>
&lt;p>Instead of trailing length, let our event generator be a function &lt;code>f: U -&amp;gt; [0, 1]&lt;/code>. If a function was chosen randomly from a family of eligible functions, we could expect that for any fixed stream, &lt;code>&amp;lt;f(x_1), f(x_2), ...&amp;gt;&lt;/code> would be uniformly random between 0 and 1. Now our definition of &amp;ldquo;rarity&amp;rdquo; is the smallest of &lt;code>f(x_i)&lt;/code>s. In a stream of 1000 elements, the smallest element you saw was 0.7?, I don&amp;rsquo;t think there are that many elements. Even if there were 2 unique elements, we should have seen the numbers &lt;code>&amp;lt; 0.5&lt;/code> with 0.75 probability. On the other hand, in a stream of 1000 elements, the smallest element you saw was 0.01?, looks like there are many unique elements.&lt;/p>
&lt;p>What exactly is many? Well as per this algorithm, on average, if the smallest number was &lt;code>s&lt;/code>, there were &lt;code>1/s - 1&lt;/code> unique elements in the stream. To answer why exactly this number, you might want to read &lt;a href="https://www.sketchingbigdata.org/fall20/lec/notes.pdf">these lecture notes.&lt;/a> Now this is not an exact answer, but with high probability it is close to the correct answer. If we want to be more certain, compute the number using different randomly picked functions then compute the average. Using the Law of Large numbers, as more and more experiments we do, the average gets closer and closer to the correct answer.&lt;/p>
&lt;h2 id="implementation">Implementation&lt;/h2>
&lt;h3 id="ingredients">Ingredients&lt;/h3>
&lt;ol>
&lt;li>A stream, (you know, to test the implementation.)&lt;/li>
&lt;li>Around say a thousand, randomly picked functions of the form &lt;code>U -&amp;gt; [0, 1]&lt;/code>&lt;/li>
&lt;/ol>
&lt;p>For the stream, I will use &lt;a href="https://en.wikipedia.org/wiki/War_and_Peace">Leo Tolstoy&amp;rsquo;s War and Peace&lt;/a>. You can download one from &lt;a href="https://www.gutenberg.org/files/2600/2600-0.txt">Project Gutenberg&lt;/a>. I will use &lt;a href="https://spacy.io/">spaCy&lt;/a> to preprocess the text.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> spacy.lang.en &lt;span style="color:#f92672">import&lt;/span> English
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">with&lt;/span> open(&lt;span style="color:#e6db74">&amp;#39;./data/war_and_peace.txt&amp;#39;&lt;/span>) &lt;span style="color:#66d9ef">as&lt;/span> f:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> data &lt;span style="color:#f92672">=&lt;/span> f&lt;span style="color:#f92672">.&lt;/span>read()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>nlp &lt;span style="color:#f92672">=&lt;/span> English(max_length&lt;span style="color:#f92672">=&lt;/span>len(data))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>doc &lt;span style="color:#f92672">=&lt;/span> nlp(data)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>stream &lt;span style="color:#f92672">=&lt;/span> [token&lt;span style="color:#f92672">.&lt;/span>lower_ &lt;span style="color:#66d9ef">for&lt;/span> token &lt;span style="color:#f92672">in&lt;/span> doc
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> &lt;span style="color:#f92672">not&lt;/span> (token&lt;span style="color:#f92672">.&lt;/span>is_punct &lt;span style="color:#f92672">or&lt;/span> token&lt;span style="color:#f92672">.&lt;/span>is_space)]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print(&lt;span style="color:#e6db74">&amp;#39; &amp;#39;&lt;/span>&lt;span style="color:#f92672">.&lt;/span>join(stream[&lt;span style="color:#ae81ff">1000&lt;/span>:&lt;span style="color:#ae81ff">1010&lt;/span>]))
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-text" data-lang="text">&lt;span style="display:flex;">&lt;span>speaker was the well known anna pávlovna schérer maid of
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>To pick a function, first I generate 64 random bits, and then xor them with &lt;code>hash(token)&lt;/code> which is also 64 bit long on modern machines. First I will write a function that can generate many such &amp;ldquo;functions&amp;rdquo; in a batch.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> random
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">initialise_hash_fn&lt;/span>(n, seed&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">42&lt;/span>):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> masks &lt;span style="color:#f92672">=&lt;/span> []
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">for&lt;/span> i &lt;span style="color:#f92672">in&lt;/span> range(n):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> random&lt;span style="color:#f92672">.&lt;/span>seed(seed&lt;span style="color:#f92672">+&lt;/span>i)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> masks&lt;span style="color:#f92672">.&lt;/span>append(random&lt;span style="color:#f92672">.&lt;/span>getrandbits(&lt;span style="color:#ae81ff">64&lt;/span>))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> masks
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>masks &lt;span style="color:#f92672">=&lt;/span> initialise_hash_fn(&lt;span style="color:#ae81ff">1000&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>But xor gives me a number between 0 and 2^64-1, I need between 0 and 1. So will have to divide the resultant hash by 2^64-1.&lt;/p>
&lt;p>Finally, I process the stream. I&amp;rsquo;ve a thousand masks for thousand random functions.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">get_estimates&lt;/span>(masks, stream):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> masks &lt;span style="color:#f92672">=&lt;/span> np&lt;span style="color:#f92672">.&lt;/span>array(masks, dtype&lt;span style="color:#f92672">=&lt;/span>np&lt;span style="color:#f92672">.&lt;/span>uint64)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> stream &lt;span style="color:#f92672">=&lt;/span> np&lt;span style="color:#f92672">.&lt;/span>array([hash(t) &lt;span style="color:#66d9ef">for&lt;/span> t &lt;span style="color:#f92672">in&lt;/span> stream], dtype&lt;span style="color:#f92672">=&lt;/span>np&lt;span style="color:#f92672">.&lt;/span>uint64)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> mx &lt;span style="color:#f92672">=&lt;/span> np&lt;span style="color:#f92672">.&lt;/span>iinfo(np&lt;span style="color:#f92672">.&lt;/span>uint64)&lt;span style="color:#f92672">.&lt;/span>max
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> mn &lt;span style="color:#f92672">=&lt;/span> np&lt;span style="color:#f92672">.&lt;/span>ones(len(masks))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">for&lt;/span> element &lt;span style="color:#f92672">in&lt;/span> stream:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> s &lt;span style="color:#f92672">=&lt;/span> (masks &lt;span style="color:#f92672">^&lt;/span> element)&lt;span style="color:#f92672">/&lt;/span>mx
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> mn &lt;span style="color:#f92672">=&lt;/span> np&lt;span style="color:#f92672">.&lt;/span>where(mn &lt;span style="color:#f92672">&amp;lt;&lt;/span> s, mn, s)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> mn
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>estimates_raw &lt;span style="color:#f92672">=&lt;/span> get_estimates(masks, stream)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>estimate_raw &lt;span style="color:#f92672">=&lt;/span> np&lt;span style="color:#f92672">.&lt;/span>mean(estimates_raw)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print(&lt;span style="color:#ae81ff">1&lt;/span>&lt;span style="color:#f92672">/&lt;/span>estimate_raw &lt;span style="color:#f92672">-&lt;/span> &lt;span style="color:#ae81ff">1&lt;/span>, len(set(stream)))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># prints, 18117.553711596098 17982&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>So the actual answer is 17,982 and the estimated answer is 18,117. Error of around 150, not bad!&lt;/p>
&lt;p>We can also see the effect of using more and more random functions below.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>cumsum &lt;span style="color:#f92672">=&lt;/span> estimates_raw&lt;span style="color:#f92672">.&lt;/span>cumsum()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>z &lt;span style="color:#f92672">=&lt;/span> np&lt;span style="color:#f92672">.&lt;/span>arange(len(cumsum)) &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#ae81ff">1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>estimates &lt;span style="color:#f92672">=&lt;/span> cumsum&lt;span style="color:#f92672">/&lt;/span>z
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>estimates &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">1&lt;/span>&lt;span style="color:#f92672">/&lt;/span>estimates &lt;span style="color:#f92672">-&lt;/span> &lt;span style="color:#ae81ff">1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>plt&lt;span style="color:#f92672">.&lt;/span>plot(z, estimates)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>plt&lt;span style="color:#f92672">.&lt;/span>axhline(true_n_uniq, c&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;r&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;img src="images/cumulative_effects.png" alt="plot">&lt;/p></content></item><item><title>About Me</title><link>https://dhruvpatel.dev/about/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://dhruvpatel.dev/about/</guid><description>Hi, I am Dhruv. As a Senior Data Scientist at Myntra, I work on personalised size recommendation models. I graduated from the department of Computer Science and Automation at Indian Institute of Science in 2019. There I worked mostly on image segmentation problem and little bit on using machine learning on graph like structures.
You can reach out to me at hello at domain.</description><content>&lt;p>Hi, I am Dhruv. As a Senior Data Scientist at &lt;a href="https://www.myntra.com">Myntra&lt;/a>, I work on personalised size recommendation models. I graduated from the department of Computer Science and Automation at Indian Institute of Science in 2019. There I worked mostly on image segmentation problem and little bit on using machine learning on graph like structures.&lt;/p>
&lt;p>You can reach out to me at &lt;code>hello at domain&lt;/code>.&lt;/p></content></item><item><title>Talks I have given</title><link>https://dhruvpatel.dev/talks/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://dhruvpatel.dev/talks/</guid><description>Monte Carlo Markov Chains and PyMC3 The talk given at Myntra starts with an introduction to the Bayesian Linear Regression. I explain analytic solution and also introduce PyMC3 based solution. Then I proceed to explain Markov Chains that were used by PyMC internally. In the process Metropolis-Hastings and Gibbs chain are explained. The notebook is available here. For proofs there is a supplementary pdf.
On Double Precision Floating Points In this talk, I introduced subtleties of using floating points to the audience.</description><content>&lt;h2 id="monte-carlo-markov-chains-and-pymc3">Monte Carlo Markov Chains and PyMC3&lt;/h2>
&lt;p>The talk given at Myntra starts with an introduction to the Bayesian Linear Regression. I explain analytic solution and also introduce PyMC3 based solution. Then I proceed to explain Markov Chains that were used by PyMC internally. In the process Metropolis-Hastings and Gibbs chain are explained. The notebook is available &lt;a href="https://github.com/DhruvPatel01/myntra_talks/blob/master/bayesian_intro_with_pymc.ipynb">here&lt;/a>. For proofs there is a &lt;a href="https://github.com/DhruvPatel01/myntra_talks/blob/master/mcmc.pdf">supplementary pdf&lt;/a>.&lt;/p>
&lt;h2 id="on-double-precision-floating-points">On Double Precision Floating Points&lt;/h2>
&lt;p>In this talk, I introduced subtleties of using floating points to the audience. Talk starts with a classic mistake done in the Patriot Missile system, which caused the lives of 28 soldiers. Then I introduce a naive/intuitive algorithm of computing variance online (i.e. in one pass) and dangers of it. While explaining what caused the issues in the naive algorithm, I explain how different programming languages might give different results while working with floats(doubles). I then explain the Achilles&amp;rsquo; heel of floating point arithmetic called catastrophic calculation, and how to avoid it. Talk concludes with Welford&amp;rsquo;s algorithm on computing variance online. Slides are available &lt;a href="https://dhruvpatel.dev/slides/floats.slides.html">here&lt;/a>.&lt;/p></content></item></channel></rss>