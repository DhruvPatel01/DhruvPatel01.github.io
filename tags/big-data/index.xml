<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>big data on Dhruv Patel</title><link>https://dhruvpatel.dev/tags/big-data/</link><description>Recent content in big data on Dhruv Patel</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><copyright>Dhruv Patel</copyright><lastBuildDate>Mon, 29 Mar 2021 14:36:16 +0530</lastBuildDate><atom:link href="https://dhruvpatel.dev/tags/big-data/index.xml" rel="self" type="application/rss+xml"/><item><title>How to find the number of unique elements in a stream?</title><link>https://dhruvpatel.dev/posts/flajolet-martin/</link><pubDate>Mon, 29 Mar 2021 14:36:16 +0530</pubDate><guid>https://dhruvpatel.dev/posts/flajolet-martin/</guid><description>So, I&amp;rsquo;ve been reading about streaming algorithms. Seems like the journey to streaming algorithms(aka Algorithms for Big Data) starts with the Flajolet-Martin algorithm.
The Problem We are given a sequence &amp;lt;u_0, u_1, u_2, u_3, ... , u_n&amp;gt; of n elements. Each u_i comes from the fixed set U of some finite size. We want to see how many elements are unique.
A simple Python code like below can solve the problem, if we have required memory.</description><content>&lt;p>So, I&amp;rsquo;ve been reading about streaming algorithms. Seems like the journey to streaming algorithms(aka Algorithms for Big Data) starts with the Flajolet-Martin algorithm.&lt;/p>
&lt;h2 id="the-problem">The Problem&lt;/h2>
&lt;p>We are given a sequence &lt;code>&amp;lt;u_0, u_1, u_2, u_3, ... , u_n&amp;gt;&lt;/code> of &lt;code>n&lt;/code> elements. Each &lt;code>u_i&lt;/code> comes from the fixed set &lt;code>U&lt;/code> of some finite size. We want to see how many elements are unique.&lt;/p>
&lt;p>A simple Python code like below can solve the problem, if we have required memory.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">card&lt;/span>(seq):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> len(set(seq))
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>But we might not have a required memory. Hence we need to make a tradeoff. Use little memory and get an approximate answer or use &lt;code>O(|U|)&lt;/code> memory, and get the accurate answer. We will go with a small memory.&lt;/p>
&lt;h2 id="flajolet-martin-algorithm-a-handwavy-explanation">Flajolet-Martin Algorithm (a handwavy explanation)&lt;/h2>
&lt;p>The idea behind the FM algorithm is that each element generates an event. Same element has the same event associated with it. So if &lt;code>x_2 == x&lt;/code> generates &lt;code>blahblah&lt;/code>, and &lt;code>x_100 == x&lt;/code>, &lt;code>blahblah&lt;/code> will be generated. Summary is that you look for an event that is rare. Now if the events are generated from uniform distribution, as we see more and more &amp;ldquo;rare&amp;rdquo; events, we can be confident that we have seen &amp;ldquo;more&amp;rdquo; unique elements.&lt;/p>
&lt;p>Let me give an example. Say our event is the number of trailing zeros of the hash of the incoming element. So if the hash is &lt;code>101010&lt;/code>, the trail length is 1. On average how many different hashes would you have to see to see a trail length of 1? It&amp;rsquo;s a coin toss, on average you would have to toss a coin twice to get Heads. What if we wanted 5 heads and 1 tail? You would have to toss a coin 64 times to see that event.&lt;/p>
&lt;p>Wikipedia, Chapter-4 of Mining Massive Datasets, an original paper, and numerous other blogs describe this algorithm, so I won&amp;rsquo;t. I tried to implement this algorithm using the trail length as an event, but even with using 1000 hash functions I wasn&amp;rsquo;t able to get a reasonably close answer. So I will describe and implement what I believe is a better version of the same algorithm.&lt;/p>
&lt;p>Instead of trailing length, let our event generator be a function &lt;code>f: U -&amp;gt; [0, 1]&lt;/code>. If a function was chosen randomly from a family of eligible functions, we could expect that for any fixed stream, &lt;code>&amp;lt;f(x_1), f(x_2), ...&amp;gt;&lt;/code> would be uniformly random between 0 and 1. Now our definition of &amp;ldquo;rarity&amp;rdquo; is the smallest of &lt;code>f(x_i)&lt;/code>s. In a stream of 1000 elements, the smallest element you saw was 0.7?, I don&amp;rsquo;t think there are that many elements. Even if there were 2 unique elements, we should have seen the numbers &lt;code>&amp;lt; 0.5&lt;/code> with 0.75 probability. On the other hand, in a stream of 1000 elements, the smallest element you saw was 0.01?, looks like there are many unique elements.&lt;/p>
&lt;p>What exactly is many? Well as per this algorithm, on average, if the smallest number was &lt;code>s&lt;/code>, there were &lt;code>1/s - 1&lt;/code> unique elements in the stream. To answer why exactly this number, you might want to read &lt;a href="https://www.sketchingbigdata.org/fall20/lec/notes.pdf">these lecture notes.&lt;/a> Now this is not an exact answer, but with high probability it is close to the correct answer. If we want to be more certain, compute the number using different randomly picked functions then compute the average. Using the Law of Large numbers, as more and more experiments we do, the average gets closer and closer to the correct answer.&lt;/p>
&lt;h2 id="implementation">Implementation&lt;/h2>
&lt;h3 id="ingredients">Ingredients&lt;/h3>
&lt;ol>
&lt;li>A stream, (you know, to test the implementation.)&lt;/li>
&lt;li>Around say a thousand, randomly picked functions of the form &lt;code>U -&amp;gt; [0, 1]&lt;/code>&lt;/li>
&lt;/ol>
&lt;p>For the stream, I will use &lt;a href="https://en.wikipedia.org/wiki/War_and_Peace">Leo Tolstoy&amp;rsquo;s War and Peace&lt;/a>. You can download one from &lt;a href="https://www.gutenberg.org/files/2600/2600-0.txt">Project Gutenberg&lt;/a>. I will use &lt;a href="https://spacy.io/">spaCy&lt;/a> to preprocess the text.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> spacy.lang.en &lt;span style="color:#f92672">import&lt;/span> English
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">with&lt;/span> open(&lt;span style="color:#e6db74">&amp;#39;./data/war_and_peace.txt&amp;#39;&lt;/span>) &lt;span style="color:#66d9ef">as&lt;/span> f:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> data &lt;span style="color:#f92672">=&lt;/span> f&lt;span style="color:#f92672">.&lt;/span>read()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>nlp &lt;span style="color:#f92672">=&lt;/span> English(max_length&lt;span style="color:#f92672">=&lt;/span>len(data))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>doc &lt;span style="color:#f92672">=&lt;/span> nlp(data)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>stream &lt;span style="color:#f92672">=&lt;/span> [token&lt;span style="color:#f92672">.&lt;/span>lower_ &lt;span style="color:#66d9ef">for&lt;/span> token &lt;span style="color:#f92672">in&lt;/span> doc
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> &lt;span style="color:#f92672">not&lt;/span> (token&lt;span style="color:#f92672">.&lt;/span>is_punct &lt;span style="color:#f92672">or&lt;/span> token&lt;span style="color:#f92672">.&lt;/span>is_space)]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print(&lt;span style="color:#e6db74">&amp;#39; &amp;#39;&lt;/span>&lt;span style="color:#f92672">.&lt;/span>join(stream[&lt;span style="color:#ae81ff">1000&lt;/span>:&lt;span style="color:#ae81ff">1010&lt;/span>]))
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-text" data-lang="text">&lt;span style="display:flex;">&lt;span>speaker was the well known anna pávlovna schérer maid of
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>To pick a function, first I generate 64 random bits, and then xor them with &lt;code>hash(token)&lt;/code> which is also 64 bit long on modern machines. First I will write a function that can generate many such &amp;ldquo;functions&amp;rdquo; in a batch.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> random
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">initialise_hash_fn&lt;/span>(n, seed&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">42&lt;/span>):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> masks &lt;span style="color:#f92672">=&lt;/span> []
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">for&lt;/span> i &lt;span style="color:#f92672">in&lt;/span> range(n):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> random&lt;span style="color:#f92672">.&lt;/span>seed(seed&lt;span style="color:#f92672">+&lt;/span>i)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> masks&lt;span style="color:#f92672">.&lt;/span>append(random&lt;span style="color:#f92672">.&lt;/span>getrandbits(&lt;span style="color:#ae81ff">64&lt;/span>))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> masks
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>masks &lt;span style="color:#f92672">=&lt;/span> initialise_hash_fn(&lt;span style="color:#ae81ff">1000&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>But xor gives me a number between 0 and 2^64-1, I need between 0 and 1. So will have to divide the resultant hash by 2^64-1.&lt;/p>
&lt;p>Finally, I process the stream. I&amp;rsquo;ve a thousand masks for thousand random functions.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">get_estimates&lt;/span>(masks, stream):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> masks &lt;span style="color:#f92672">=&lt;/span> np&lt;span style="color:#f92672">.&lt;/span>array(masks, dtype&lt;span style="color:#f92672">=&lt;/span>np&lt;span style="color:#f92672">.&lt;/span>uint64)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> stream &lt;span style="color:#f92672">=&lt;/span> np&lt;span style="color:#f92672">.&lt;/span>array([hash(t) &lt;span style="color:#66d9ef">for&lt;/span> t &lt;span style="color:#f92672">in&lt;/span> stream], dtype&lt;span style="color:#f92672">=&lt;/span>np&lt;span style="color:#f92672">.&lt;/span>uint64)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> mx &lt;span style="color:#f92672">=&lt;/span> np&lt;span style="color:#f92672">.&lt;/span>iinfo(np&lt;span style="color:#f92672">.&lt;/span>uint64)&lt;span style="color:#f92672">.&lt;/span>max
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> mn &lt;span style="color:#f92672">=&lt;/span> np&lt;span style="color:#f92672">.&lt;/span>ones(len(masks))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">for&lt;/span> element &lt;span style="color:#f92672">in&lt;/span> stream:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> s &lt;span style="color:#f92672">=&lt;/span> (masks &lt;span style="color:#f92672">^&lt;/span> element)&lt;span style="color:#f92672">/&lt;/span>mx
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> mn &lt;span style="color:#f92672">=&lt;/span> np&lt;span style="color:#f92672">.&lt;/span>where(mn &lt;span style="color:#f92672">&amp;lt;&lt;/span> s, mn, s)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> mn
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>estimates_raw &lt;span style="color:#f92672">=&lt;/span> get_estimates(masks, stream)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>estimate_raw &lt;span style="color:#f92672">=&lt;/span> np&lt;span style="color:#f92672">.&lt;/span>mean(estimates_raw)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print(&lt;span style="color:#ae81ff">1&lt;/span>&lt;span style="color:#f92672">/&lt;/span>estimate_raw &lt;span style="color:#f92672">-&lt;/span> &lt;span style="color:#ae81ff">1&lt;/span>, len(set(stream)))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># prints, 18117.553711596098 17982&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>So the actual answer is 17,982 and the estimated answer is 18,117. Error of around 150, not bad!&lt;/p>
&lt;p>We can also see the effect of using more and more random functions below.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>cumsum &lt;span style="color:#f92672">=&lt;/span> estimates_raw&lt;span style="color:#f92672">.&lt;/span>cumsum()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>z &lt;span style="color:#f92672">=&lt;/span> np&lt;span style="color:#f92672">.&lt;/span>arange(len(cumsum)) &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#ae81ff">1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>estimates &lt;span style="color:#f92672">=&lt;/span> cumsum&lt;span style="color:#f92672">/&lt;/span>z
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>estimates &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">1&lt;/span>&lt;span style="color:#f92672">/&lt;/span>estimates &lt;span style="color:#f92672">-&lt;/span> &lt;span style="color:#ae81ff">1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>plt&lt;span style="color:#f92672">.&lt;/span>plot(z, estimates)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>plt&lt;span style="color:#f92672">.&lt;/span>axhline(true_n_uniq, c&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;r&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;img src="images/cumulative_effects.png" alt="plot">&lt;/p></content></item></channel></rss>